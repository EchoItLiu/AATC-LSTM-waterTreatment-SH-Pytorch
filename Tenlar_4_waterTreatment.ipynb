{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Experiment for Time-consistent Elastic Net with Least-angle Regression (TENLar) vs 9 Baseline Models for Water Treatment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSet import DataSet\n",
    "import config_final\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import logging\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, CuDNNLSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training + Validating All Models, and Predicting for Shanghai SMI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Water:\n",
    "    def __init__(self, excel_files):\n",
    "        self.source = DataSet(excel_files)\n",
    "\n",
    "\"\"\" ***************Structure All Model Instances***************\"\"\"\n",
    "    def build_model(self, method, source):        \n",
    "        if method=='TENlar':\n",
    "            opt, D = self.cv_TENlar(source.train_x, source.train_y, source.ts_x)\n",
    "            alp = opt['alpha']\n",
    "            best_params_score = opt['combine_params']\n",
    "            best_params_group = best_params_score[0:3]\n",
    "            model = LassoLars(alpha = alp, max_iter=1000)\n",
    "            return model, D, best_params_group\n",
    "                               \n",
    "        if method=='ENlar':\n",
    "            opt = self.cv_ENlar(source.train_x, source.train_y)\n",
    "            alp = opt['alpha']\n",
    "            best_params_group = opt['combine_params'][0:2]\n",
    "            model = LassoLars(alpha = alp, max_iter=1000)\n",
    "            return model, best_params_group\n",
    "                    \n",
    "        if method=='lasso':\n",
    "            model = LassoCV(alphas=[1e-3,1e-2,1e-1,1,1e1,1e2,1e3], cv=2, max_iter=50)            \n",
    "            return model\n",
    "        \n",
    "        if method=='xgboost':\n",
    "            xgb_model = xgb.XGBRegressor()\n",
    "            model = GridSearchCV(xgb_model,\n",
    "                       {'learning_rate':[0.09],\n",
    "                        'n_estimators':[700],\n",
    "                        'max_depth':[6]                 \n",
    "                       },cv=5,verbose=1)                       \n",
    "            return model\n",
    "        \n",
    "        if method=='lightgbm':\n",
    "            estimator = lgb.LGBMRegressor()\n",
    "            param_grid = {'learning_rate':[0.1],\n",
    "                          'n_estimators':[20],                      \n",
    "                          'num_leaves':[6]\n",
    "                          }\n",
    "            model = GridSearchCV(estimator, param_grid,cv=5)\n",
    "            return model\n",
    "            \n",
    "        if method=='mlr':\n",
    "            model = LinearRegression()\n",
    "            return model\n",
    "       \n",
    "        if method=='ridge_regression':\n",
    "            model = RidgeCV(alphas=[1e-2,1e-1,1,1e1,1e2], cv=5)\n",
    "            return model\n",
    "\n",
    "        if method=='random_forest':\n",
    "            opt = self.cv_RandomForestRegressor(source.train_x, source.train_y)\n",
    "            model = RandomForestRegressor(**opt)\n",
    "            return model\n",
    "            \n",
    "        if method=='mlp':\n",
    "            n, m = source.train_x.shape\n",
    "            model = Sequential()\n",
    "            model.add(Dense(512, activation='relu', input_dim=m))\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(Dense(1))\n",
    "            adam = Adam(lr=1e-4)\n",
    "            model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "            return model\n",
    "                      \n",
    "        if method=='nn':\n",
    "            n, m = source.train_x.shape\n",
    "            model = Sequential()\n",
    "            model.add(Dense(512, activation='relu', input_dim=m))\n",
    "            model.add(Dense(1))\n",
    "            adam = Adam(lr=1e-4)\n",
    "            model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "            return model\n",
    "    \n",
    "    \"\"\" ***************Validating for TENLar***************\"\"\"\n",
    "    def self.cv_TENlar(self, x, y, xts):\n",
    "        opt = {}        \n",
    "        ## set hyperparameters for TENLar \n",
    "        lamda1 = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1,1.2e-1,1.4e-1,1.6e-1,1.8e-1,2e-1,2.2e-1,2.4e-1,2.6e-1,2.8e-1, 3e-1, 3.1e-1, 3.2e-1, 3.23e-1, 3.25e-1, 3.27e-1, 3.3e-1, 3.35e-1, 3.5e-1]\n",
    "        lamda2 = [0, 9e-3, 7e-3, 6e-3, 3e-3, 1e-2, 2e-2, 5e-2, 8e-2, 1e-1, 1.1e-1, 1.2e-1, 1.3e-1, 1.4e-1, 1.5e-1, 1.6e-1, 1.7e-1, 1.8e-1, 2e-1, 2.1e-1, 2.3e-1, 2.5e-1]\n",
    "        lamda3 = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0, 2e-1,8e-1, 1]        \n",
    "        ## pre augmented data                \n",
    "        m = x.shape[1]\n",
    "        m_ts, n_ts = xts.shape        \n",
    "        # set sequence length of segment in augmented time-series data       \n",
    "        l_ts = 4000   #4000\n",
    "        # 4 segments\n",
    "        ts_no = round(m_ts / l_ts)        \n",
    "        # init residual matrix D and segmented residual matrix D\n",
    "        D = []\n",
    "        D_seg = np.zeros([l_ts, n_ts])                       \n",
    "        # init begin index \n",
    "        idb_ts = 0 \n",
    "               \n",
    "        #  calculating difference between two time-continuous samples as segment\n",
    "        for sp in range(ts_no):\n",
    "            temp_ts = xts[idb_ts:(idb_ts + l_ts),:]           \n",
    "            tmp_m = temp_ts.shape[0]              \n",
    "            for cs in range(tmp_m-1):\n",
    "                D_seg[cs,:] = temp_ts[(cs + 1),:] - temp_ts[cs,:]        \n",
    "            D.append(D_seg)            \n",
    "            idb_ts = idb_ts + l_ts\n",
    "                    \n",
    "        # init alpha (lambda1 + lambda2) and lambda3 \n",
    "        alps = []\n",
    "        alp = 0              \n",
    "        # init iterations and save parameters combination and corresponding score to list\n",
    "        k = len(lamda1)\n",
    "        f = len(lamda2)\n",
    "        b = len(lamda3)\n",
    "        comb_params_score = []\n",
    "        comb_scores = []\n",
    "        comb_params = []             \n",
    "        # init scores list for calculating R^2\n",
    "        scores = []        \n",
    "        score = 0\n",
    "        \n",
    "        # Tuning parameters in grid\n",
    "        for u in range(k):\n",
    "            for v in range(f):\n",
    "                for w in range(b):\n",
    "                    \n",
    "                ## get argumented time-series segmented data\n",
    "                    # random number for selecting segment randomly\n",
    "                    seg_no = np.random.randint(0,ts_no)                    \n",
    "                    current_D = D[seg_no]   \n",
    "                                                        \n",
    "                ## lar_lasso → lar_supervisedElasticNet \n",
    "                     # alpha \n",
    "                    alp = lamda1[u] / math.sqrt(1 + lamda2[v]) \n",
    "                                          \n",
    "                   ## concat (trainX,trainY) to convert lar_lasso to TENLar                                 \n",
    "                      # structure time-consistent term\n",
    "                      # detect abrupt change of turbidity and counting\n",
    "                    turbidity = current_D[:,1]\n",
    "                      # set a threshold of abrupt change 20NTU \n",
    "                    abrupt_threshold = 20\n",
    "                    turbidity_ab_temp = (turbidity * (turbidity > abrupt_threshold))>0\n",
    "                    turbidity_ab_no = (turbidity_ab_temp[turbidity_ab_temp==True]).shape[0]\n",
    "                    average_ab_no = 100\n",
    "      \n",
    "                      # define and set decay parameter\n",
    "                    a_s = (1- (average_ab_no / current_D.shape[0])) * 10\n",
    "                      # calculating time-consistent term\n",
    "                    current_D = math.sqrt(a_s * lamda3[w]) * current_D  \n",
    "                      # calculating unit term \n",
    "                    I = math.sqrt(lamda2[v]) * np.eye(m)                   \n",
    "                    ctD_m = current_D.shape[0]\n",
    "                    z0 = np.zeros([ctD_m + m])\n",
    "                    \n",
    "                     # cat trainX and trainY for converting\n",
    "                    trainX = np.concatenate((x, I, current_D), 0)\n",
    "                    trainY = np.concatenate((y, z0), 0)\n",
    "                     # cat trainX and alpha for converting free parameters β implementing “elastic”\n",
    "                    trainX = 1 / math.sqrt(1 + lamda2[v]) * trainX \n",
    "                    # struct Lar_ElasticNet model using current hyperparameter\n",
    "                    clf = LassoLars(alpha = alp, max_iter = 1000)\n",
    "                    current_model = clf.fit(trainX, trainY)\n",
    "\n",
    "                    score = current_model.score(x, y, None)\n",
    "                    scores.append(score)\n",
    "\n",
    "                    # save 3 hyperparameters\n",
    "                    comb_params_score.append(np.array([lamda1[u], lamda2[v] ,lamda3[w], score]))\n",
    "                    comb_scores.append(np.array([u, v, w, score]))\n",
    "                    comb_params.append((u, v, w))\n",
    "                    alps.append(alp)\n",
    "                \n",
    "        # list → numpy\n",
    "        scores = np.array(scores)\n",
    "        # returns the index that would sort an array(default: ascending order)\n",
    "        idx = np.argsort(scores)\n",
    "        \n",
    "        # print best score \n",
    "        best_score = scores[idx[-1]]\n",
    "        print ('best_score:', best_score)        \n",
    "        print ('-'*16)       \n",
    "        # select highest score and corresponding hyperparameters\n",
    "        opt['combine_params'] = comb_params_score[idx[-1]]\n",
    "        opt['alpha'] = alps[idx[-1]]\n",
    "        return opt, D\n",
    "                    \n",
    "        \n",
    "    \"\"\" Tuning params in grid for ENLar\"\"\"     \n",
    "    def cv_ENlar(self,x,y):\n",
    "        \n",
    "        opt = {}\n",
    "        lamda1 = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1,1.2e-1,1.4e-1,1.6e-1,1.8e-1,2e-1,2.2e-1,2.4e-1,2.6e-1,2.8e-1, 3e-1, 3.1e-1, 3.2e-1, 3.23e-1, 3.25e-1, 3.27e-1, 3.3e-1,3.35e-1,3.5e-1]\n",
    "        lamda2 = [1e-3,1e-2,1e-1,0,1,1e1,1e2,1e3]       \n",
    "        alps = []\n",
    "        alp = 0        \n",
    "        k = len(lamda1)\n",
    "        f = len(lamda2)\n",
    "        comb_params_score = []\n",
    "        comb_scores = []\n",
    "        comb_params = []                       \n",
    "        scores = []        \n",
    "        score = 0\n",
    "        \n",
    "        for u in range(k):\n",
    "            for v in range(f):\n",
    "                alp = lamda1[u] / math.sqrt(1 + lamda2[v]) \n",
    "                m = x.shape[1]\n",
    "                I = math.sqrt(lamda2[v]) * np.eye(m)\n",
    "                z0 = np.zeros([m])\n",
    "                trainX = np.concatenate((x, I), 0)\n",
    "                trainY = np.concatenate((y, z0), 0)\n",
    "                trainX =  trainX * 1/math.sqrt(1 + lamda2[v]) \n",
    "                clf = LassoLars(alpha = alp, max_iter = 1000)\n",
    "                current_model = clf.fit(trainX, trainY)                \n",
    "                score = current_model.score(x, y, None)\n",
    "                scores.append(score)                \n",
    "                comb_params_score.append(np.array([lamda1[u], lamda2[v], score]))                \n",
    "                comb_scores.append(np.array([u, v, score]))\n",
    "                comb_params.append((u,v))                \n",
    "                alps.append(alp)                \n",
    "        scores = np.array(scores)\n",
    "        idx = np.argsort(scores)\n",
    "        best_score = scores[idx[-1]]\n",
    "        opt['alpha'] = alps[idx[-1]]\n",
    "        opt['combine_params'] = comb_params_score[idx[-1]]\n",
    "        return opt\n",
    "           \n",
    "    def cv_RandomForestRegressor(self, x, y):\n",
    "        m_f = x.shape[0]\n",
    "        parameters_lists = {'max_features': list(range(9,x.shape[1],9)),\n",
    "                            'max_depth':[16,64,256],\n",
    "                           'n_estimators':[128]\n",
    "                            }\n",
    "        opt = {}\n",
    "        for (pname,plist) in parameters_lists.items():\n",
    "            k = len(plist)\n",
    "            scores = np.zeros([k])\n",
    "            for p in range(k):\n",
    "                argues = dict(opt)\n",
    "                argues[pname] = plist[p]\n",
    "                clf = RandomForestRegressor(**argues)\n",
    "                scores[p] = np.mean(cross_validation.cross_val_score(clf,x,y,cv=5,scoring='neg_mean_squared_error'))\n",
    "            idx = np.argsort(scores)\n",
    "            opt[pname] = plist[idx[k-1]]\n",
    "        return opt\n",
    "    \n",
    "    \"\"\"**************Experiments and Predicting**************\"\"\"      \n",
    "    def run_experiments(self, methods, experiments, repeat_num, metrics):\n",
    "        results = {}\n",
    "        for exp_name in experiments.keys():\n",
    "            exp = experiments[exp_name]\n",
    "            train_time, test_time = exp['times']\n",
    "            evaluation = np.zeros([repeat_num, len(exp['lag_time']), len(exp['clustering']), len(exp['normalize']), len(methods), len(metrics)])\n",
    "            print ('repeat_num:',repeat_num)\n",
    "                        \n",
    "            for r in range(repeat_num):\n",
    "                for i,lag_time in enumerate(exp['lag_time']):\n",
    "                    for j,clustering in enumerate(exp['clustering']):\n",
    "                        for k,normalize in enumerate(exp['normalize']):\n",
    "                            \n",
    "                            # time-series data\n",
    "                            self.source.attr2source(train_time, \n",
    "                                                    normalize,\n",
    "                                                    0, \n",
    "                                                    lag_time,\n",
    "                                                    data_type='time-series')                            \n",
    "                            \n",
    "                            # general training data\n",
    "                            self.source.attr2source(train_time, \n",
    "                                                    normalize,\n",
    "                                                    clustering, \n",
    "                                                    lag_time,\n",
    "                                                    data_type='train')\n",
    "                            # general testing data\n",
    "                            self.source.attr2source(test_time,\n",
    "                                                     normalize, \n",
    "                                                     clustering, \n",
    "                                                     lag_time,\n",
    "                                                     data_type='test')                            \n",
    "                            \n",
    "                            ensemble_y = 0\n",
    "                            for t, method in enumerate(methods):\n",
    "                                if method == 'ensemble':\n",
    "                                    predict_y = ensemble_y / (len(methods)-1.0)\n",
    "                                    \n",
    "                                else:                                \n",
    "                                # structure model every time\n",
    "                                    if method == 'TENlar':\n",
    "                                        model, D, best_params_group = self.build_model(method, self.source)                                                                  \n",
    "                                        # Training\n",
    "                                         # get optimized hyper-parameters\n",
    "                                        lambda1 = best_params_group[0]\n",
    "                                        lambda2 = best_params_group[1]\n",
    "                                        lambda3 = best_params_group[2]\n",
    "                                        \n",
    "                                        # construct trainX and trainY\n",
    "                                        ts_seg_no = len(D) \n",
    "                                        ts_no = np.random.randint(0,ts_seg_no)\n",
    "                                        D_no = D[ts_no]\n",
    "                                        exp_ab_no = 100\n",
    "                                        a_s = (1- (exp_ab_no / D_no.shape[0])) * 10\n",
    "                                        vald_D = math.sqrt(a_s * lambda3) * D_no\n",
    "                                        vald_I = math.sqrt(lambda2) * np.eye((self.source.train_x.shape[1]))\n",
    "                                        valdD_m = vald_D.shape[0]\n",
    "                                        unlabel_y = np.zeros([valdD_m + (self.source.train_x.shape[1])])\n",
    "                                        \n",
    "                                        trainX = np.concatenate((self.source.train_x, vald_I, vald_D), 0)\n",
    "                                        trainY = np.concatenate((y, unlabel_y), 0)\n",
    "#                                         train_X = np.concatenate((self.source.train_x, self.source.ts_x), 0)\n",
    "#                                         train_Y = np.concatenate((self.source.train_y, self.source.ts_y), 0)                              \n",
    "                                        \n",
    "                                        # fit general parameters\n",
    "                                        model = model.fit(train_X, train_Y)\n",
    "                                        predict_y = model.predict(self.source.test_x)                        \n",
    "                                                                            \n",
    "             \n",
    "                                    elif method == 'ENLar':\n",
    "                                        model, best_params_group = self.build_model(method, self.source)\n",
    "                                        lambda2 = best_params_group[1]\n",
    "                                        # structure trainX and trainY        \n",
    "                                        cv_I = math.sqrt(lambda2) * np.eye((self.source.train_x.shape[1]))\n",
    "                                        unlab_y = np.zeros([(self.source.train_x.shape[1])])\n",
    "                                        trainX = np.concatenate((self.source.train_x, cv_I), 0)\n",
    "                                        trainY = np.concatenate((y, unlab_y), 0)\n",
    "                                        model = model.fit(trainX, trainY)\n",
    "                                        predict_y = model.predict(self.source.test_x)                        \n",
    "                          \n",
    "                                    elif method == 'mlp' or method == 'nn':\n",
    "                                        model = self.build_model(method, self.source) \n",
    "                                        model.fit(self.source.ts_x[0:1500, :], self.source.ts_y[0:1500], \n",
    "                                                  epochs=200, batch_size=128,\n",
    "                                                  verbose=0\n",
    "                                                 )\n",
    "                                        \n",
    "                                        predict_y = model.predict(self.source.test_x)\n",
    "                                    \n",
    "\n",
    "                                    else:\n",
    "                                        model = self.build_model(method, self.source)\n",
    "                                        model = model.fit(self.source.train_x, self.source.train_y)\n",
    "                                        predict_y = model.predict(self.source.test_x)\n",
    "                                    ensemble_y += predict_y.reshape([-1, 1])\n",
    "                                        \n",
    "                                evaluation[r, i, j, k, t, :] = self.evaluate(predict_y, self.source.test_y, metrics)\n",
    "                                print('exp_name={}, lag_time={}, normalize={}, clustering={}, method={} :{}'.format(\n",
    "                                    exp_name, lag_time, normalize, clustering, method, evaluation[r, i, j, k, t, :]))\n",
    "                                \n",
    "            # save results as a dictionary \n",
    "            np.save('result/{}.npy'.format(exp_name), evaluation)            \n",
    "#             results[exp_name] = evaluation\n",
    "\n",
    "\n",
    "    \"\"\"**************Grapth Experiments**************\"\"\"\n",
    "    def specify_experiments(self, methods, experiments):\n",
    "        results0 = {}\n",
    "        exp = experiments['spring']\n",
    "        train_time, test_time = exp['times']\n",
    "        self.source.attr2source(train_time,0,0,10,data_type='train')\n",
    "        self.source.attr2source(test_time,0,0,10,data_type='test')\n",
    "        \n",
    "        # save GT coagulant dosage in traindata and testdata\n",
    "        GT_test = self.source.test_y\n",
    "        GT_train = self.source.train_y\n",
    "        \n",
    "        # save all needed predicted results\n",
    "        predicted_results_test = np.zeros( [len(methods), 1000])\n",
    "        predicted_results_train = np.zeros( [len(methods), 1000])\n",
    "        \n",
    "                \n",
    "        ensemble_y_train = 0\n",
    "        ensemble_y_test = 0\n",
    "        for t, method in enumerate(methods):\n",
    "            if method == 'ensemble':\n",
    "                predict_y_train = ensemble_y_train / (len(methods)-1.0)\n",
    "                predict_y_test = ensemble_y_test / (len(methods)-1.0)\n",
    "\n",
    "            else:                                                \n",
    "                # fit model, then get predicted results using traindata and testdata \n",
    "                if method == 'TENLar':\n",
    "                    model, D, best_params_group  = self.build_model(method, self.source)\n",
    "                    model = model.fit(self.source.train_x, self.source.train_y)\n",
    "                    predict_y_test = model.predict(self.source.test_x)\n",
    "                    predict_y_train = model.predict(self.source.train_x) \n",
    "                    \n",
    "                \n",
    "                elif method == 'ENLar':\n",
    "                    model, best_params_group = self.build_model(method, self.source)\n",
    "                    model = model.fit(self.source.train_x, self.source.train_y)\n",
    "                    predict_y_test = model.predict(self.source.test_x)\n",
    "                    predict_y_train = model.predict(self.source.train_x)                    \n",
    "                                                            \n",
    "                elif method == 'mlp' or method == 'nn':\n",
    "                    model = self.build_model(method, self.source)\n",
    "                    model.fit(self.source.train_x, self.source.train_y, \n",
    "                              epochs=200, batch_size=128,\n",
    "                              verbose=0)\n",
    "                    # get predicted results using testdata\n",
    "                    predict_y_test = model.predict(self.source.test_x)\n",
    "                    # get predicted results using traindata\n",
    "                    predict_y_train = model.predict(self.source.train_x)\n",
    "\n",
    "                else:\n",
    "                    model = self.build_model(method, self.source)\n",
    "                    model = model.fit(self.source.train_x, self.source.train_y)\n",
    "                    predict_y_test = model.predict(self.source.test_x)\n",
    "                    predict_y_train = model.predict(self.source.train_x)\n",
    "                    \n",
    "                ensemble_y_test += predict_y_test.reshape([-1, 1])\n",
    "                ensemble_y_train += predict_y_train.reshape([-1, 1])\n",
    "                \n",
    "            predicted_results_test[t, :] = predict_y_test.reshape(1000,)\n",
    "            predicted_results_train[t, :] = predict_y_train.reshape(1000,)\n",
    "        return GT_test, GT_train, predicted_results_test, predicted_results_train    \n",
    "    \n",
    "        \n",
    "    \"\"\"**************Utility**************\"\"\"     \n",
    "    def evaluate(self, pred_y, true_y, metrics):\n",
    "        pred_y = pred_y.reshape([-1])\n",
    "        true_y = true_y.reshape([-1])\n",
    "        metrics_num = len(metrics)\n",
    "        results = np.zeros([metrics_num])\n",
    "        for i,metric in enumerate(metrics):\n",
    "            if metric == 'rmse':\n",
    "                results[i] = np.sqrt(np.mean(np.power(pred_y - true_y,2)))\n",
    "            elif metric == 'mape':\n",
    "                results[i] = np.mean(np.abs(true_y - pred_y) / true_y)*100\n",
    "            elif metric == 'correlation':\n",
    "                results[i] = np.corrcoef(pred_y, true_y)[0,1]\n",
    "            elif metric == 'wi':\n",
    "                results[i] = np.sum(np.power(true_y - pred_y, 2)) / np.sum(np.power(np.abs(pred_y - np.mean(true_y)) + np.abs(true_y-np.mean(true_y)), 2))\n",
    "        return results        \n",
    "    \n",
    "    def decimal2round2(self, results):\n",
    "        sh = results.shape\n",
    "        fraction = results.reshape(-1)\n",
    "        for m in range(len(fraction)):\n",
    "            fraction[m] = round(fraction[m],8)\n",
    "        fractions = fraction.reshape(sh)\n",
    "        return fractions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable Interface and CUDA selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(config_final.path)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "m = Water(config_final.excel_files)\n",
    "m.run_experiments(config_final.methods, \n",
    "                  config_final.experiments,\n",
    "                  config_final.repeat_num,\n",
    "                  config_final.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Models on RMSEs and Rs of Aluminum Doses in Different Time-lagged Terms of Autumn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "styles = ['r*--','b*--', 'm>-', 'y<-', 'c^-', 'ms-', 'yv-', 'b+-', 'gh-','k-', 'c*--']\n",
    "methods_fmt = ['Semi-Supervised_LAR_ElasticNet', 'LAR_ElasticNet', 'Lasso','XGBoost','LightGBM', 'MLR', 'Ridge_Regression', 'Random_Forest', 'MLP','NN', 'Ensemble']\n",
    "\n",
    "os.chdir(config_final.path)\n",
    "\n",
    "result = np.load(osp.join('result', 'spring.npy')).squeeze()\n",
    "\n",
    "# print ('results:', results)\n",
    "\n",
    "# mean experiment times\n",
    "results = result.mean(0)\n",
    "\n",
    "# result shape = [lag_time, methods]→RMSE\n",
    "rmse_results = results[:, :, 0]\n",
    "# result shape = [lag_time, methods]→Correlation\n",
    "correlation_results = results[:, :, 2]\n",
    "\n",
    "# create a new figure instance[Figure], figsize is width, height(in inches) of Figure\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "\n",
    "# dding sub-plot instance(Axes) and its coordinate axis [left, bottom, width, height]\n",
    "ax1 = fig.add_axes([0.1, 0.1, 1.2, 1.2])\n",
    "ax2 = fig.add_axes([0.2, 0.7, 0.5, 0.5])\n",
    "\n",
    "# ploting Figure\n",
    "for j,method in enumerate(methods_fmt):\n",
    "\n",
    "    # 6 lags for same method to plot x:lags  y:RMSE\n",
    "#         [2,4,6,8,10,12]\n",
    "    ax1.plot(np.array([2,4,6,8,12,14]),rmse_results[:, j], styles[j],linewidth = 2.5, label=method)\n",
    "    ax2.plot(np.array([2,4,6,8,12,14]),correlation_results[:, j], styles[j], label=method)\n",
    "    \n",
    "# set grid    \n",
    "# ax1.grid()\n",
    "# ax2.grid()\n",
    "# set text and axis of Figure\n",
    "# ax1\n",
    "ax1.set_title('The Effect of Previous Aluminum Doses in Autumn', fontsize=14)\n",
    "ax1.set_xlim(-1,15)\n",
    "# ax1.xticks(np.linspace(-np.pi,np.pi,20))\n",
    "ax1.set_ylim(0,3)\n",
    "ax1.set_xlabel('The Number of Previous Timesteps(t)',fontsize=14)\n",
    "ax1.set_ylabel('RMSE',fontsize=14)\n",
    "\n",
    "#ax2\n",
    "ax2.set_ylabel('Correlation',fontsize=14)\n",
    "ax2.set_xlim(-1,15)\n",
    "ax2.set_ylim(-0.5,3)\n",
    "\n",
    "ax1.legend(loc = 'upper right')\n",
    "\n",
    "# save\n",
    "os.chdir('/home/yqliu/Yiwei_water/results')\n",
    "fig.savefig('PAD in Autumn.pdf', bbox_inches='tight', pad_inches=0.2, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Models on RMSEs and Rs of Aluminum Doses in Different Time-lagged Terms of Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(9,7))\n",
    "styles = ['r*--','b*--', 'm>-', 'y<-', 'c^-', 'ms-', 'yv-', 'b+-', 'gh-','k-', 'c*--']\n",
    "\n",
    "methods_fmt = ['LAR_ElasticNet', 'Lasso','XGBoost','LightGBM', 'MLR', 'Ridge_Regression', 'Random_Forest', 'MLP','NN', 'Ensemble']\n",
    "\n",
    "os.chdir(config_final.path)\n",
    "\n",
    "result = np.load(osp.join('result', 'winter.npy')).squeeze()\n",
    "\n",
    "# mean experiment times\n",
    "results = result.mean(0)\n",
    "\n",
    "# result shape = [lag_time, methods]→RMSE\n",
    "rmse_results = results[:, :, 0]\n",
    "# result shape = [lag_time, mehtods]→Wi\n",
    "wi_results = results[:, :, 3]\n",
    "\n",
    "# create a new figure instance[Figure], figsize is width, height(in inches) of Figure\n",
    "fig = plt.figure(figsize = (9, 7))\n",
    "\n",
    "# dding sub-plot instance(Axes) and its coordinate axis [left, bottom, width, height]\n",
    "ax1 = fig.add_axes([0.1, 0.1, 1.2, 1.2])\n",
    "ax2 = fig.add_axes([0.2, 0.7, 0.5, 0.5])\n",
    "\n",
    "# ploting Figure\n",
    "for j,method in enumerate(methods_fmt):\n",
    "\n",
    "    # 6 lags for same method to plot x:lags  y:RMSE\n",
    "#         [2,4,6,8,10,12]\n",
    "    ax1.plot(np.array([2,4,6,8,10,12]),rmse_results[:, j], styles[j], linewidth = 2.5, label=method)\n",
    "    ax2.plot(np.array([2,4,6,8,10,12]),wi_results[:, j], styles[j], label=method)\n",
    "    \n",
    "# set grid    \n",
    "# ax1.grid()\n",
    "# ax2.grid()\n",
    "# set text and axis of Figure\n",
    "# ax1\n",
    "ax1.set_title('The Effect of Previous Aluminum Doses in Winter', fontsize=14)\n",
    "ax1.set_xlim(-1,13)\n",
    "ax1.set_ylim(0,8)\n",
    "ax1.set_xlabel('The Number of Previous Timesteps(t)',fontsize=14)\n",
    "ax1.set_ylabel('RMSE',fontsize=14)\n",
    "\n",
    "#ax2\n",
    "ax2.set_ylabel('WI',fontsize=14)\n",
    "ax2.set_xlim(-1,13)\n",
    "ax2.set_ylim(-0.5,2)\n",
    "\n",
    "ax1.legend(loc = 'upper right')\n",
    "\n",
    "# save\n",
    "os.chdir('/home/yqliu/Yiwei_water/results')\n",
    "fig.savefig('PAD in water.pdf' , bbox_inches='tight', pad_inches=0.2, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Comparison Between Measured and Predictive Dosage of 10 Methods in Testing and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all random result data\n",
    "GT_test, GT_train, predicted_results_test, predicted_results_train = m.specify_experiments(config_final.methods, config_final.experiments)\n",
    "print (\"loading completely...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "  \n",
    "# print ('predicted_results_test_shape:', predicted_results_test.shape) \n",
    "# print ('predicted_results_test:',predicted_results_test)\n",
    "    \n",
    "# set sample number\n",
    "sample_number = 150 \n",
    "L = np.arange(sample_number)                                                                                           \n",
    "                                                                                           \n",
    "# set random sample_id                                                                                            \n",
    "sample_id = np.random.randint(0,(1000 - sample_number + 1) )\n",
    "\n",
    "print ('sample_id:',sample_id)\n",
    "                                                                                           \n",
    "fig = plt.figure(figsize=(9,6))\n",
    "styles = ['r-','b-', 'k-', 'y-', 'c-', 'm-', 'y-', 'b-', 'g-','c--']\n",
    "methods_fmt = ['LAR_ElasticNet', 'Lasso','XGBoost','LightGBM', 'MLR', 'Ridge_Regression', 'Random_Forest', 'MLP','NN', 'Ensemble']\n",
    "\n",
    "os.chdir(config_final.path)\n",
    "\n",
    "\n",
    "# create a new figure instance[Figure], figsize is width, height(in inches) of Figure\n",
    "fig = plt.figure(figsize = (13, 7))\n",
    "\n",
    "# adding sub-plot instance(Axes) and its coordinate axis [left, bottom, width, height]\n",
    "ax1 = fig.add_axes([0.1, 0.1, 1.2, 1.2])\n",
    "ax2 = fig.add_axes([0.2, 0.77, 0.5, 0.5])\n",
    "\n",
    "\n",
    "# vv = predicted_results_test[j, sample_id:(sample_id+sample_number)]\n",
    "# print ('vv_shape:',vv.shape)\n",
    "\n",
    "# ploting Figure\n",
    "for j,method in enumerate(methods_fmt):\n",
    "\n",
    "    # use random predicted result data for training and testing\n",
    "    ax1.plot(L,predicted_results_test[j, sample_id:(sample_id+sample_number)], styles[j], linewidth = 1, label=method)                                                                                                                                                                                      \n",
    "    ax2.plot(L,predicted_results_train[j, sample_id:(sample_id+sample_number)], styles[j], linewidth = 1, label=method)\n",
    "\n",
    "# use random GT result data for training and testing\n",
    "ax1.plot(L,GT_test[sample_id:(sample_id+sample_number)], 'k:', linewidth = 1.5, label='optimal')                                                                                                                                                                                      \n",
    "ax2.plot(L,GT_train[sample_id:(sample_id+sample_number)], 'k:', linewidth = 1.5, label='optimal')                                                                                                                                                                                      \n",
    "                                                                                           \n",
    "\n",
    "                                                                                           \n",
    "# set grid    \n",
    "# ax1.grid()\n",
    "# ax2.grid()\n",
    "# set text and axis of Figure\n",
    "# ax1\n",
    "ax1.set_title('The Scatterplot of Measured/Calculated Coagulant Doses in Traing and Testing', fontsize=14)\n",
    "ax1.set_xlim(-1,160)\n",
    "ax1.set_ylim(20,80)\n",
    "ax1.set_xlabel('N-th Sample(Testing)',fontsize=14)\n",
    "ax1.set_ylabel('Coagulant Dosage(mg/L)',fontsize=14)\n",
    "\n",
    "#ax2\n",
    "ax2.set_xlabel('N-th Sample(Training)',fontsize=14)                                                                                           \n",
    "ax2.set_xlim(-1,160)\n",
    "ax2.set_ylim(20,80)\n",
    "\n",
    "ax1.legend(loc = 'upper right')\n",
    "\n",
    "# save\n",
    "os.chdir('/home/yqliu/Yiwei_water/results')\n",
    "fig.savefig('Measured and calculated CD_pic.pdf', bbox_inches='tight', pad_inches=0.2, dpi=300)\n",
    "# plt.savefig('previous.png',bbox_inches='tight', pad_inches=0.2, dpi = 300)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The changes of features in a period of time.  RW: raw water, SW: sedimentation water, C: carbon-processed water..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random data(15.5.5-15.5.7) and non-normalized\n",
    "m.source.attr2source([('2015-05-05 00:00:00','2015-05-07 00:00:00')], 0, 0, 3, data_type='all')\n",
    "a = m.source.all_x\n",
    "b = m.source.all_y\n",
    "print ('a_shape:',a.shape)\n",
    "print ('b_shape:',b.shape)\n",
    "print (\"loading completely...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,25))\n",
    "\n",
    "axes = plt.subplot(9,1,1)\n",
    "plt.plot(a[:,0], 'r-', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel('RW-Nitrite (mg/L)',fontsize = 15)\n",
    "plt.grid(True)\n",
    "\n",
    "axes = plt.subplot(9,1,2)\n",
    "plt.plot(a[:,1], 'b-', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel('RW-Conductivity (mg/L)',fontsize = 15)\n",
    "plt.grid(True)\n",
    "\n",
    "axes = plt.subplot(9,1,3)\n",
    "plt.plot(a[:,2], 'm-', linewidth = 1.8)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel('RW-pH',fontsize = 15)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(9,1,4)\n",
    "plt.plot(a[:,3], 'c-', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel('RW-Turbidity',fontsize = 15)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(9,1,5)\n",
    "plt.plot(a[:,4], 'm-', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel('RW-Dissolved Oxygen',fontsize = 15)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(9,1,6)\n",
    "plt.plot(a[:,5], 'r-', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel('SW-Turbidity',fontsize = 15)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(9,1,7)\n",
    "plt.plot(a[:,6], 'b--',linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel('SW-Dissolved Oxygen',fontsize = 15)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(9,1,8)\n",
    "plt.plot(a[:,7], 'c--', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel('C-Turbidity',fontsize = 15)\n",
    "plt.grid(True)\n",
    "\n",
    "    \n",
    "plt.subplot(9,1,9)\n",
    "plt.plot(b, 'k-', linewidth = 2)\n",
    "sns.despine()\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel('Optimal coagulant dosage',fontsize = 15)\n",
    "plt.xlabel('Sample',fontsize = 15)\n",
    "plt.grid(True)\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "# save .pdf\n",
    "os.chdir('/home/yqliu/Yiwei_water/results')\n",
    "fig.savefig('Fetures_values_pic.pdf', bbox_inches='tight', pad_inches=0.2, dpi=300)\n",
    "plt.show() \n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
