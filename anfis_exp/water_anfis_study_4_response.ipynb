{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Selection on ANFIS \n",
    "# Comparison Experiments for ANFIS and NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "from DataSet import DataSet\n",
    "\n",
    "## ANFIS: premise and consequent parameter selecting\n",
    "from models import ANFIS_premise\n",
    "from models import ANFIS_consequent\n",
    "\n",
    "\n",
    "## NN + MLP\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, CuDNNLSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "import config\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import os\n",
    "import math\n",
    "import logging\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Water:\n",
    "    def __init__(self, excel_files):\n",
    "        self.source = DataSet(excel_files)\n",
    "        \n",
    "      # parameters selecting (grid search)\n",
    "      \n",
    "    def build_model(self, method, source):\n",
    "        \n",
    "        if method == 'ANFIS_PRE':\n",
    "            \n",
    "            pre_parameters_group, anfis_pre_rmse = self.premise_validation(source)            \n",
    "            return pre_parameters_group, anfis_pre_rmse            \n",
    "                \n",
    "        if method == 'ANFIS_CON':\n",
    "            \n",
    "            anfis_final_rmse = self.consequent_validation(source, pre_parameters_group)          \n",
    "            return anfis_final_rmse\n",
    "        \n",
    "        if method=='NN':\n",
    "            \n",
    "            # grid search\n",
    "            nn_layer_list = [3,6,9]\n",
    "            rmse_scores = []\n",
    "            for k in range(len(nn_layer_list)):\n",
    "                \n",
    "                n, m = source.x_train.shape\n",
    "                model = Sequential()\n",
    "                adam = Adam(lr = 1e-3)\n",
    "                \n",
    "                if nn_layer_list[k]==3:\n",
    "                    model.add(Dense(512, activation='relu', input_dim = m))\n",
    "                    model.add(Dense(128, activation='relu'))\n",
    "                    model.add(Dense(1))\n",
    "                \n",
    "                if nn_layer_list[k]==6\n",
    "                    model.add(Dense(512, activation='relu', input_dim = m))\n",
    "                    model.add(Dense(256, activation='relu'))\n",
    "                    model.add(Dense(128))\n",
    "                    model.add(Dense(64, activation='relu', input_dim = m))\n",
    "                    model.add(Dense(32, activation='relu'))\n",
    "                    model.add(Dense(1))\n",
    "                    \n",
    "                if nn_layer_list[k]==6\n",
    "                    model.add(Dense(1024, activation='relu', input_dim = m))\n",
    "                    model.add(Dense(512, activation='relu'))\n",
    "                    model.add(Dense(256))\n",
    "                    model.add(Dense(128, activation='relu', input_dim = m))\n",
    "                    model.add(Dense(64, activation='relu'))\n",
    "                    model.add(Dense(32))\n",
    "                    model.add(Dense(16, activation='relu', input_dim = m))\n",
    "                    model.add(Dense(8, activation='relu'))\n",
    "                    model.add(Dense(4))\n",
    "                    model.add(Dense(2, activation='relu', input_dim = m))\n",
    "                    model.add(Dense(2, activation='relu'))\n",
    "                    model.add(Dense(1))                        \n",
    "                \n",
    "                model.compile(loss='mean_squared_error', optimizer = adam)\n",
    "                model.fit(self.source.nn_trainX, self.source.nn_trainY, \n",
    "                                                  epochs = 100,\n",
    "                                                  verbose = 0\n",
    "                                                 )\n",
    "\n",
    "                pred_y = model.predict(source.nn_testX)\n",
    "\n",
    "                nn_rmse = self.evaluate(pred_y, self.source.nn_testY, metrics)[:1]\n",
    "                rmse_scores.append(nn_rmse)\n",
    "                \n",
    "                ## ranking\n",
    "                idx = np.argsort(rmse_scores)\n",
    "                nn_final_rmse = rmse_scores[idx[0]]                \n",
    "            \n",
    "            return nn_final_rmse\n",
    "                \n",
    "        if method=='MLP':\n",
    "                        \n",
    "            n, m = source.x_train.shape\n",
    "            model = Sequential()\n",
    "            model.add(Dense(512, activation='relu', input_dim = m))\n",
    "            model.add(Dense(128, activation='relu'))\n",
    "            model.add(Dense(1))\n",
    "            adam = Adam(lr = 1e-3)\n",
    "            model.compile(loss='mean_squared_error', optimizer = adam)\n",
    "            model.fit(self.source.nn_trainX, self.source.nn_trainY, \n",
    "                                              epochs = 100,\n",
    "                                              verbose = 0\n",
    "                                             )\n",
    "            \n",
    "            pred_y = model.predict(source.nn_testX)\n",
    "            \n",
    "            mlp_rmse = self.evaluate(pred_y, self.source.nn_testY, metrics)[:1]\n",
    "            \n",
    "            \n",
    "            return mlp_rmse  \n",
    "        \n",
    "        \n",
    "        if method=='MLR':\n",
    "            \n",
    "            model = LinearRegression()  \n",
    "            model = model.fit(self.source.nn_trainX, self.source.nn_trainY)\n",
    "            pred_y = model.predict(source.nn_testX)\n",
    "            mlr_rmse = self.evaluate(pred_y, self.source.nn_testY, metrics)[:1]\n",
    "            \n",
    "            return mlr_rmse\n",
    "        \n",
    "               \n",
    "    def premise_validation(self, source):\n",
    "        \n",
    "        # test set\n",
    "        testX = source.x_anfis_test\n",
    "        testY = source.y_anfis_test\n",
    "        \n",
    "        # train set\n",
    "        train_X = source.x_anfis_train\n",
    "        train_Y = source.y_anfis_train\n",
    "\n",
    "        inputSize = train_X.size(1)\n",
    "\n",
    "        # init\n",
    "        Anfis = ANFIS_premise(inputSize, 1).cuda().double()\n",
    "        optim_anf = torch.optim.Adam(Anfis.parameters(), lr = 1e-3)\n",
    "        mseLoss = nn.MSELoss()\n",
    "\n",
    "        # other variables and hyperparameters \n",
    "        train_epoch = 100\n",
    "        validation_interval == 5\n",
    "        loss_sum = 0\n",
    "        count = 0\n",
    "        flag = 0\n",
    "        best_score = 1000\n",
    "\n",
    "        flatten_test = 20\n",
    "        \n",
    "        ## saving optimized premise parameters and metric\n",
    "        anfis_metric = np.zeros([4])\n",
    "        anfis_pre_params_group = []\n",
    "\n",
    "\n",
    "        # training\n",
    "        for i in range(train_epoch):                               \n",
    "            optim_anf.zero_grad()\n",
    "            y_hat = Anfis(train_X)                \n",
    "            anfis_loss = mseLoss(y_hat, train_Y)\n",
    "            anfis_loss.backward()\n",
    "            optim_anf.step()\n",
    "\n",
    "\n",
    "            #  validating\n",
    "            if (i >= 10&& i % validation_interval==0):\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    y_pred = Anfis(testX)                                                   \n",
    "                    rmse_score_anf = self.evaluate(y_pred, testY, 'rmse')\n",
    "                    mape_score_anf = self.evaluate(y_pred, testY, 'mape')\n",
    "                    corr_score_anf = self.evaluate(y_pred, testY, 'correlation')\n",
    "                    wi_score_anf = self.evaluate(y_pred, testY, 'wi')\n",
    "\n",
    "\n",
    "                if rmse_score_anf < best_score:\n",
    "                    # save current best\n",
    "                    rmse_score_anf_cbest = rmse_score_anf\n",
    "                    mape_score_anf_cbest = mape_score_anf\n",
    "                    corr_score_anf_cbest = corr_score_anf\n",
    "                    wi_score_anf_cbest = wi_score_anf\n",
    "\n",
    "                    \"\"\"---print and save rmse and corresponding premise parameter---\"\"\"\n",
    "                    # anfis premise parameters\n",
    "                    anfis_params_dic = Anfis.state_dict()\n",
    "                    # all weights\n",
    "                    anfis_weights_list = list(anfis_params_dic.values())\n",
    "                    \n",
    "                    # all premise parameters\n",
    "                    anfis_pre_params = anfis_weights_list[1]\n",
    "                    anfis_pre_params_group = [np.array(pre) for i, pre enumerate (anfis_pre_params) if i<10]\n",
    "                    \n",
    "                    \n",
    "                    best_score = rmse_score_anf_cbest\n",
    "                    print (\"current epoch:\", i)\n",
    "\n",
    "\n",
    "        # average MSE/MAPE/Correlation/WI score \n",
    "        anfis_metric[0] = rmse_score_anf_cbest\n",
    "        anfis_metric[1] = mape_score_anf_cbest\n",
    "        anfis_metric[2] = corr_score_anf_cbest\n",
    "        anfis_metric[3] = wi_score_anf_cbest\n",
    "\n",
    "        return anfis_pre_params_group, best_score \n",
    "    \n",
    "      \n",
    "    def consequent_validation(self, source, pre_params_group):\n",
    "        \n",
    "        # test set\n",
    "        testX = source.x_anfis_test\n",
    "        testY = source.y_anfis_test\n",
    "        \n",
    "        # train set\n",
    "        train_X = source.x_anfis_train\n",
    "        train_Y = source.y_anfis_train\n",
    "\n",
    "        inputSize = train_X.size(1)\n",
    "        \n",
    "        \"\"\"hyperparameters FC layer list\"\"\"\n",
    "        fc_layer_list = [1,3,6,9]\n",
    "        \n",
    "        \n",
    "        for u in range(len(hyper_list)):\n",
    "            Anfis = ANFIS_consequent(inputSize, 1, pre_params_group, fc_layer_list[u]).cuda().double()\n",
    "            \n",
    "            \"\"\"frozen premise parameters\"\"\"\n",
    "            for param in Anfis.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "            for param in model.fc1.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            for param in model.fc2.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            ##  only BP fc1 and fc2\n",
    "            optim_anf = torch.optim.Adam(filter(lambda p: p.requires_grad, Anfis.parameters()), lr = 1e-3)\n",
    "            mseLoss = nn.MSELoss()\n",
    "\n",
    "            # other variables and hyperparameters \n",
    "            train_epoch = 100\n",
    "            validation_interval == 5\n",
    "            loss_sum = 0\n",
    "            count = 0\n",
    "            flag = 0\n",
    "            best_score = 1000\n",
    "\n",
    "            flatten_test = 20\n",
    "\n",
    "            ## saving optimized premise parameters and metric\n",
    "            anfis_metric = np.zeros([4])\n",
    "            anfis_pre_params_group = []\n",
    "            # all remse for all consequent parameters\n",
    "            rmse_scores = [] \n",
    "\n",
    "            # training\n",
    "            for i in range(train_epoch):                               \n",
    "                optim_anf.zero_grad()\n",
    "                y_hat = Anfis(train_X)                \n",
    "                anfis_loss = mseLoss(y_hat, train_Y)\n",
    "                anfis_loss.backward()\n",
    "                optim_anf.step()\n",
    "\n",
    "\n",
    "                #  validating\n",
    "                if (i >= 10&& i % validation_interval==0):\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        y_pred = Anfis(testX)                                                   \n",
    "                        rmse_score_anf = self.evaluate(y_pred, testY, 'rmse')\n",
    "                        mape_score_anf = self.evaluate(y_pred, testY, 'mape')\n",
    "                        corr_score_anf = self.evaluate(y_pred, testY, 'correlation')\n",
    "                        wi_score_anf = self.evaluate(y_pred, testY, 'wi')\n",
    "\n",
    "\n",
    "                    if rmse_score_anf < best_score:\n",
    "                        # save current best\n",
    "                        rmse_score_anf_cbest = rmse_score_anf\n",
    "                        mape_score_anf_cbest = mape_score_anf\n",
    "                        corr_score_anf_cbest = corr_score_anf\n",
    "                        wi_score_anf_cbest = wi_score_anf\n",
    "\n",
    "                        \"\"\"---print and save rmse and corresponding premise parameter---\"\"\"\n",
    "                        # anfis premise parameters\n",
    "                        anfis_params_dic = Anfis.state_dict()\n",
    "                        # all weights\n",
    "                        anfis_weights_list = list(anfis_params_dic.values())\n",
    "\n",
    "                        # all premise parameters\n",
    "                        anfis_pre_params = anfis_weights_list[1]\n",
    "                        anfis_pre_params_group = [np.array(pre) for i, pre enumerate (anfis_pre_params) if i<10]\n",
    "\n",
    "                        best_score = rmse_score_anf_cbest\n",
    "                        print (\"current epoch:\", i)\n",
    "\n",
    "\n",
    "            # average MSE/MAPE/Correlation/WI score \n",
    "            anfis_metric[0] = rmse_score_anf_cbest\n",
    "            anfis_metric[1] = mape_score_anf_cbest\n",
    "            anfis_metric[2] = corr_score_anf_cbest\n",
    "            anfis_metric[3] = wi_score_anf_cbest\n",
    "            \n",
    "            rmse_scores.append(rmse_score_anf_cbest)\n",
    "            \n",
    "        ## ranking\n",
    "        idx = np.argsort(rmse_scores)\n",
    "        best_rmse = rmse_scores[idx[0]]\n",
    "                      \n",
    "        return best_rmse \n",
    "    \n",
    "    \n",
    "        \n",
    "            \n",
    "    \n",
    "    def evaluate(self, pred_y, true_y, metrics):\n",
    "        pred_y = pred_y.reshape([-1])\n",
    "        true_y = true_y.reshape([-1])\n",
    "        metrics_num = len(metrics)\n",
    "        results = np.zeros([metrics_num])\n",
    "        for i,metric in enumerate(metrics):\n",
    "            if metric == 'rmse':\n",
    "                results[i] = np.sqrt(np.mean(np.power(pred_y - true_y,2)))\n",
    "            elif metric == 'mape':\n",
    "                results[i] = np.mean(np.abs(true_y - pred_y) / true_y)*100\n",
    "            elif metric == 'correlation':\n",
    "                results[i] = np.corrcoef(pred_y, true_y)[0,1]\n",
    "            elif metric == 'wi':\n",
    "                results[i] = np.sum(np.power(true_y - pred_y, 2)) / np.sum(np.power(np.abs(pred_y - np.mean(true_y)) + np.abs(true_y-np.mean(true_y)), 2))\n",
    "        return results      \n",
    "          \n",
    "       \n",
    "    def run_experiments(self, methods, experiments, repeat_num, metrics):\n",
    "        # dic type\n",
    "        results = {}\n",
    "        for exp_name in experiments.keys():\n",
    "            # exp_name is dict_keys type\n",
    "            exp = experiments[exp_name]\n",
    "            train_time, test_time = exp['times']\n",
    "            evaluation = np.zeros([repeat_num, len(exp['lag_time']), len(exp['clustering']), len(exp['normalize']), len(methods), (len(metrics)-3)])\n",
    "            print ('repeat_num:',repeat_num)\n",
    "                        \n",
    "            for r in range(repeat_num):\n",
    "                for i,lag_time in enumerate(exp['lag_time']):\n",
    "                    for j,clustering in enumerate(exp['clustering']):\n",
    "                        for k,normalize in enumerate(exp['normalize']):\n",
    "                            \n",
    "                                   \n",
    "                            # print and saving all ablative models\n",
    "                            for t, method in enumerate(methods):\n",
    "                                                                                                   \n",
    " \n",
    "                                self.source.attr2source(train_time, \n",
    "                                                        normalize,\n",
    "                                                        0, \n",
    "                                                        lag_time,\n",
    "                                                        data_type = 'time-series')                            \n",
    "\n",
    "                                \n",
    "                                self.source.attr2source(train_time, \n",
    "                                                        normalize,\n",
    "                                                        clustering, \n",
    "                                                        lag_time,\n",
    "                                                        data_type = 'ts-train')\n",
    "            \n",
    "                                self.source.attr2source(test_time,\n",
    "                                                         normalize, \n",
    "                                                         clustering, \n",
    "                                                         lag_time,\n",
    "                                                         data_type = 'ts-test')\n",
    "                                                \n",
    "                                evaluation[r, i, j, k, t, :] = self.build_model(method, self.source) \n",
    "               \n",
    "                                print('exp_name={}, lag_time={}, normalize={}, clustering={}, method={} :{}'.format(\n",
    "                                    exp_name, lag_time, normalize, clustering, method, evaluation[r, i, j, k, t, :]))\n",
    "                                \n",
    "            # save results as a dictionary \n",
    "            np.save('result/{}.npy'.format(exp_name), evaluation)            \n",
    "\n",
    "\n",
    "    def decimal2round2(self, results):\n",
    "        sh = results.shape\n",
    "        fraction = results.reshape(-1)\n",
    "        for m in range(len(fraction)):\n",
    "            fraction[m] = round(fraction[m],8)\n",
    "        fractions = fraction.reshape(sh)\n",
    "#         print ('fractions_shape',fractions.shape)\n",
    "        return fractions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(config_final.path)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "m = Water(config_final.excel_files)\n",
    "m.run_experiments(config_final.methods, \n",
    "                  config_final.experiments,\n",
    "                  config_final.repeat_num,\n",
    "                  config_final.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
