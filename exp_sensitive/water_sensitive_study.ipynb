{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for Machine Learning Models for Water Treatment \n",
    "\n",
    "### generally speaking, experimental results and stability for [random, unnormalized] are \n",
    "### better than [clustering, normalized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from DataSet_ablation import DataSet\n",
    "import config_ablation\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import logging\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# add ElasticNet and Lasso model fit with Least Angle Regression\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Adding XGBoost、LightGBM\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    " \n",
    "# Adding Multiple Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, CuDNNLSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Water:\n",
    "    def __init__(self, excel_files):\n",
    "        self.source = DataSet(excel_files)\n",
    "        \n",
    "      # only init and structure model \n",
    "    \n",
    "      # return S: time-series segments to preserve time-consistent [training]\n",
    "      # return D: time penalty term to detect abrupt change [training]\n",
    "      # return lamda3:  \\lambda_3 to adjust [grid]\n",
    "      # return alpha: alpha including (\\lambda_1) \\lambda_2 to adjust [grid]\n",
    "      # return I: augmented identity matrix [training]\n",
    "      \n",
    "    \n",
    "    def build_model(self, method, source):\n",
    "        \n",
    "        if method=='no_timeSeries_Tenlar':\n",
    "            opt, best_params_score, comb_params_score, comb_scores = self.cv_no_timeSeries_Tenlar(source.train_x, source.train_y)\n",
    "            # grid lambda1 + lambda2\n",
    "            alp = opt['alpha']\n",
    "            model = LassoLars(alpha=alp, max_iter=50)\n",
    "            # S/D/I training\n",
    "#             regressor.fit(trainX,trainY)\n",
    "            return opt, best_params_score, model,comb_params_score ,comb_scores\n",
    "        \n",
    "        if method=='no_l3Norm_Tenlar':\n",
    "            opt, best_params_score, comb_params_score, comb_scores = self.cv_no_l3Norm_Tenlar(source.train_x, source.train_y, source.ts_x)\n",
    "            alp = opt['alpha']\n",
    "            model = LassoLars(alpha=alp, max_iter=50)\n",
    "            return opt, best_params_score, model,comb_params_score ,comb_scores\n",
    "                \n",
    "        if method=='no_l2Norm_Tenlar':\n",
    "            opt, best_params_score, comb_params_score, comb_scores = self.cv_no_l2Norm_Tenlar(source.train_x, source.train_y, source.ts_x)\n",
    "            alp = opt['alpha']\n",
    "            model = LassoLars(alpha=alp, max_iter=50)\n",
    "            return opt, best_params_score, model,comb_params_score ,comb_scores\n",
    "        \n",
    "        if method=='no_IM_Tenlar':\n",
    "            opt, best_params_score, comb_params_score, comb_scores = self.cv_LarsemiSupervisedElasticNetRegressor(source.train_x, source.train_y, source.ts_x)\n",
    "            alp = opt['alpha']\n",
    "            model = LassoLars(alpha=alp, max_iter=50)\n",
    "            return opt, best_params_score, model,comb_params_score ,comb_scores\n",
    "                                           \n",
    "        if method=='full_model':\n",
    "            opt, comb_params_score, comb_scores = self.cv_full_model(source.train_x, source.train_y)\n",
    "            alp = opt['alpha']\n",
    "            model = LassoLars(alpha=alp, max_iter=50)\n",
    "            return opt, model,comb_params_score ,comb_scores\n",
    "                     \n",
    "        if method=='lasso':\n",
    "            model = LassoCV(alphas=[1e-3,1e-2,1e-1,1,1e1,1e2,1e3], cv=2, max_iter=50)            \n",
    "            return model\n",
    "        \n",
    "\n",
    "    # grid search for no_timeSeries_Tenlar\n",
    "    def cv_no_timeSeries_Tenlar(self, x, y):\n",
    "        opt = {}\n",
    "        \n",
    "        lamda1 = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 1.2e-1, 1.4e-1, 1.6e-1, 1.8e-1, 2e-1, 2.2e-1, 2.4e-1, 2.6e-1, 2.8e-1, 3e-1, 3.1e-1, 3.2e-1, 3.23e-1, 3.25e-1, 3.27e-1, 3.3e-1, 3.35e-1, 3.5e-1]\n",
    "        lamda2 = [0, 9e-3,7e-3, 6e-3, 3e-3, 1e-2, 2e-2, 5e-2, 8e-2, 1e-1, 1.1e-1, 1.2e-1, 1.3e-1, 1.4e-1, 1.5e-1, 1.6e-1, 1.7e-1, 1.8e-1, 2e-1, 2.1e-1, 2.3e-1, 2.5e-1]\n",
    "        \n",
    "        m = x.shape[1]\n",
    "       \n",
    "        alps = []\n",
    "        alp = 0\n",
    "                \n",
    "        k = len(lamda1)\n",
    "        f = len(lamda2)\n",
    "        comb_params_score = []\n",
    "        comb_scores = []\n",
    "        comb_params = []\n",
    "        \n",
    "        scores = []        \n",
    "        score = 0\n",
    "        \n",
    "        for u in range(k):\n",
    "            for v in range(f):\n",
    "  \n",
    "                alp = lamda1[u] / math.sqrt(1 + lamda2[v]) \n",
    "\n",
    "                I = math.sqrt(lamda2[v]) * np.eye(m)\n",
    "                z0 = np.zeros([m])\n",
    "\n",
    "                trainX = np.concatenate((x, I), 0)\n",
    "                trainY = np.concatenate((y, z0), 0)\n",
    "\n",
    "                trainX = 1 / math.sqrt(1 + lamda2[v]) *  trainX \n",
    "\n",
    "                clf = LassoLars(alpha = alp, max_iter = 50)\n",
    "                current_model = clf.fit(trainX, trainY)\n",
    "\n",
    "                score = current_model.score(x, y, None)\n",
    "                scores.append(score)\n",
    "                comb_params_score.append(np.array([lamda1[u], lamda2[v],score]))\n",
    "                comb_scores.append(np.array([u, v, score]))\n",
    "                comb_params.append((u, v))\n",
    "\n",
    "                alps.append(alp)\n",
    "\n",
    "        scores = np.array(scores)\n",
    "        idx = np.argsort(scores)        \n",
    "        best_score = scores[idx[-1]]\n",
    "        best_params_score = comb_params_score[idx[-1]]\n",
    "\n",
    "        opt['alpha'] = alps[idx[-1]]\n",
    "        opt['combine_params'] = comb_params[idx[-1]] \n",
    "        return opt, best_params_score, comb_params_score,comb_scores        \n",
    "\n",
    "        print ('---------------------------------------------------')\n",
    "                \n",
    "      # grid search for no_l3Norm_Tenlar\n",
    "    def cv_no_l3Norm_Tenlar(self,x, y, xts):\n",
    "        opt = {}\n",
    "        \n",
    "        lamda1 = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 1.2e-1, 1.4e-1, 1.6e-1, 1.8e-1, 2e-1, 2.2e-1, 2.4e-1, 2.6e-1, 2.8e-1, 3e-1, 3.1e-1, 3.2e-1, 3.23e-1, 3.25e-1, 3.27e-1, 3.3e-1, 3.35e-1, 3.5e-1]\n",
    "        lamda2 = [0, 9e-3,7e-3, 6e-3, 3e-3, 1e-2, 2e-2, 5e-2, 8e-2, 1e-1, 1.1e-1, 1.2e-1, 1.3e-1, 1.4e-1, 1.5e-1, 1.6e-1, 1.7e-1, 1.8e-1, 2e-1, 2.1e-1, 2.3e-1, 2.5e-1]\n",
    "        \n",
    "        m = x.shape[1]\n",
    "        m_ts, n_ts = xts.shape       \n",
    "        l_ts = 2000   \n",
    "        ts_no = round(m_ts / l_ts)\n",
    "        D = []\n",
    "        D_seg = np.zeros([l_ts,n_ts])                       \n",
    "        idb_ts = 0 \n",
    "               \n",
    "        for sp in range(ts_no):\n",
    "            \n",
    "            temp_ts = xts[idb_ts:(idb_ts + l_ts),:]\n",
    "            tmp_m = temp_ts.shape[0]              \n",
    "            for cs in range(tmp_m-1):\n",
    "                D_seg[cs,:] = temp_ts[(cs + 1),:] - temp_ts[cs,:]        \n",
    "\n",
    "            D.append(D_seg)            \n",
    "            idb_ts = idb_ts + l_ts\n",
    "            \n",
    "        alps = []\n",
    "        alp = 0\n",
    "                \n",
    "        k = len(lamda1)\n",
    "        f = len(lamda2)\n",
    "        comb_params_score = []\n",
    "        comb_scores = []\n",
    "        comb_params = []        \n",
    "        scores = []        \n",
    "        score = 0\n",
    "        \n",
    "        for u in range(k):\n",
    "            for v in range(f):\n",
    "                    \n",
    "                seg_no = np.random.randint(0,ts_no)                    \n",
    "                current_D = D[seg_no]   \n",
    "                alp = lamda1[u] / math.sqrt(1 + lamda2[v])\n",
    "\n",
    "                I = math.sqrt(lamda2[v]) * np.eye(m)\n",
    "                ctD_m = current_D.shape[0]\n",
    "                z0 = np.zeros([m + ctD_m])\n",
    "\n",
    "                trainX = np.concatenate((x, I, current_D), 0)\n",
    "                trainY = np.concatenate((y, z0), 0)\n",
    "                trainX = 1 / math.sqrt(1 + lamda2[v]) * trainX \n",
    "\n",
    "\n",
    "                clf = LassoLars(alpha = alp, max_iter = 50)\n",
    "                current_model = clf.fit(trainX, trainY)\n",
    "                score = current_model.score(x, y, None)\n",
    "                scores.append(score)\n",
    "                comb_params_score.append(np.array([lamda1[u], lamda2[v], score]))\n",
    "                comb_scores.append(np.array([u, v, score]))\n",
    "                comb_params.append((u, v))\n",
    "\n",
    "                alps.append(alp)\n",
    "\n",
    "        scores = np.array(scores)\n",
    "        idx = np.argsort(scores)\n",
    "\n",
    "        best_score = scores[idx[-1]]        \n",
    "        best_params_score = comb_params_score[idx[-1]]\n",
    "\n",
    "        opt['alpha'] = alps[idx[-1]]\n",
    "        opt['combine_params'] = comb_params[idx[-1]] \n",
    "        return opt, best_params_score, comb_params_score,comb_scores\n",
    "\n",
    "        print ('---------------------------------------------------')\n",
    "        \n",
    "\n",
    "      # grid search for no_l2Norm_Tenlar\n",
    "    def cv_no_l2Norm_Tenlar(self, x, y, xts):\n",
    "        opt = {}\n",
    "        \n",
    "        lamda1 = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 1.2e-1, 1.4e-1, 1.6e-1, 1.8e-1, 2e-1, 2.2e-1, 2.4e-1, 2.6e-1, 2.8e-1, 3e-1, 3.1e-1, 3.2e-1, 3.23e-1, 3.25e-1, 3.27e-1, 3.3e-1, 3.35e-1, 3.5e-1]\n",
    "        lamda3 = [1e-5,  1e-4, 1e-3,  1e-2, 1e-1, 0, 2e-1,8e-1, 1]\n",
    "\n",
    "        m = x.shape[1]\n",
    "        m_ts, n_ts = xts.shape       \n",
    "        l_ts = 2000   \n",
    "        ts_no = round(m_ts / l_ts)\n",
    "        D = []\n",
    "        D_seg = np.zeros([l_ts,n_ts])                       \n",
    "        idb_ts = 0 \n",
    "               \n",
    "        for sp in range(ts_no):\n",
    "            \n",
    "            temp_ts = xts[idb_ts:(idb_ts + l_ts),:]\n",
    "            tmp_m = temp_ts.shape[0]              \n",
    "            for cs in range(tmp_m-1):\n",
    "                D_seg[cs,:] = temp_ts[(cs + 1),:] - temp_ts[cs,:]        \n",
    "\n",
    "            D.append(D_seg)            \n",
    "            idb_ts = idb_ts + l_ts\n",
    "            \n",
    "        alps = []\n",
    "        alp = 0\n",
    "                \n",
    "        k = len(lamda1)\n",
    "        b = len(lamda3)\n",
    "        comb_params_score = []\n",
    "        comb_scores = []\n",
    "        comb_params = []        \n",
    "        scores = []        \n",
    "        score = 0\n",
    "        \n",
    "        for u in range(k):\n",
    "            for w in range(b):\n",
    "\n",
    "                seg_no = np.random.randint(0,ts_no)                    \n",
    "                current_D = D[seg_no]   \n",
    "                alp = lamda1[u]\n",
    "\n",
    "                I = np.eye(m)\n",
    "                ctD_m = current_D.shape[0]\n",
    "                z0 = np.zeros([m + ctD_m])\n",
    "\n",
    "                trainX = np.concatenate((x, I, current_D), 0)\n",
    "                trainY = np.concatenate((y, z0), 0)\n",
    "\n",
    "                clf = LassoLars(alpha = alp, max_iter = 50)\n",
    "                current_model = clf.fit(trainX, trainY)\n",
    "                score = current_model.score(x, y, None)\n",
    "                scores.append(score)\n",
    "                comb_params_score.append(np.array([lamda1[u], lamda3[w], score]))\n",
    "                comb_scores.append(np.array([u, w, score]))\n",
    "                comb_params.append((u, w))\n",
    "\n",
    "                alps.append(alp)\n",
    "\n",
    "        scores = np.array(scores)\n",
    "        idx = np.argsort(scores)\n",
    "\n",
    "        best_score = scores[idx[-1]]        \n",
    "        best_params_score = comb_params_score[idx[-1]]\n",
    "\n",
    "        opt['alpha'] = alps[idx[-1]]\n",
    "        opt['combine_params'] = comb_params[idx[-1]] \n",
    "        return opt, best_params_score, comb_params_score, comb_scores\n",
    "\n",
    "\n",
    "    def cv_no_IM_Tenlar(self, x, y, xts):\n",
    "        opt = {}\n",
    "        \n",
    "        lamda1 = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 1.2e-1, 1.4e-1, 1.6e-1, 1.8e-1, 2e-1, 2.2e-1, 2.4e-1, 2.6e-1, 2.8e-1, 3e-1, 3.1e-1, 3.2e-1, 3.23e-1, 3.25e-1, 3.27e-1, 3.3e-1, 3.35e-1, 3.5e-1]\n",
    "        lamda2 = [0, 9e-3,7e-3, 6e-3, 3e-3, 1e-2, 2e-2, 5e-2, 8e-2, 1e-1, 1.1e-1, 1.2e-1, 1.3e-1, 1.4e-1, 1.5e-1, 1.6e-1, 1.7e-1, 1.8e-1, 2e-1, 2.1e-1, 2.3e-1, 2.5e-1]\n",
    "        lamda3 = [1e-5,  1e-4, 1e-3,  1e-2, 1e-1, 0, 2e-1,8e-1, 1]\n",
    "                    \n",
    "        m = x.shape[1]\n",
    "        m_ts, n_ts = xts.shape       \n",
    "        l_ts = 2000  \n",
    "        ts_no = round(m_ts / l_ts)\n",
    "        D = []\n",
    "        D_seg = np.zeros([l_ts,n_ts]) \n",
    "        idb_ts = 0 \n",
    "               \n",
    "        for sp in range(ts_no):\n",
    "            \n",
    "            temp_ts = xts[idb_ts:(idb_ts + l_ts),:]\n",
    "            tmp_m = temp_ts.shape[0]              \n",
    "            for cs in range(tmp_m-1):\n",
    "                D_seg[cs,:] = temp_ts[(cs + 1),:] - temp_ts[cs,:]        \n",
    "\n",
    "            D.append(D_seg)            \n",
    "            idb_ts = idb_ts + l_ts\n",
    "        \n",
    "        alps = []\n",
    "        alp = 0\n",
    "                \n",
    "        k = len(lamda1)\n",
    "        f = len(lamda2)\n",
    "        b = len(lamda3)\n",
    "        comb_params_score = []\n",
    "        comb_scores = []\n",
    "        comb_params = []\n",
    "        scores = []        \n",
    "        score = 0\n",
    "        \n",
    "        # tuning parameters in grid\n",
    "        for u in range(k):\n",
    "            for v in range(f):\n",
    "                for w in range(b):\n",
    "                    \n",
    "                    seg_no = np.random.randint(0,ts_no)\n",
    "                    current_D = D[seg_no]    \n",
    "                    alp = lamda1[u] / math.sqrt(1 + lamda2[v]) \n",
    "\n",
    "                    current_D = math.sqrt(lamda3[w]) * current_D  \n",
    "                    ctD_m = current_D.shape[0]\n",
    "                    z0 = np.zeros([ctD_m])\n",
    "                    \n",
    "                    trainX = np.concatenate((x, current_D), 0)\n",
    "                    trainY = np.concatenate((y, z0), 0)\n",
    "                    trainX = 1 / math.sqrt(1 + lamda2[v]) *  trainX \n",
    "\n",
    "                    clf = LassoLars(alpha = alp, max_iter = 50)\n",
    "                    current_model = clf.fit(trainX, trainY)\n",
    "                    score = current_model.score(x, y, None)\n",
    "                    scores.append(score)\n",
    "\n",
    "                    comb_params_score.append(np.array([lamda1[u], lamda2[v] ,lamda3[w], score]))\n",
    "                    comb_scores.append(np.array([u, v, w, score]))\n",
    "                    comb_params.append((u, v, w))\n",
    "\n",
    "                    alps.append(alp)\n",
    "                \n",
    "        scores = np.array(scores)\n",
    "        idx = np.argsort(scores)\n",
    "        best_score = scores[idx[-1]]\n",
    "        best_params_score = comb_params_score[idx[-1]]\n",
    "        opt['alpha'] = alps[idx[-1]]\n",
    "        opt['combine_params'] = comb_params[idx[-1]] \n",
    "        return opt, best_params_score, comb_params_score,comb_scores\n",
    "    \n",
    "    print ('---------------------------------------------------')    \n",
    "\n",
    "    # tuning params in grid for entire Tenlar\n",
    "    def cv_full_model(self, x, y, xts):\n",
    "        opt = {}\n",
    "        \n",
    "        ## set hyperparameters for Tenlar \n",
    "        # best (lambda1, lambda2, lambda3) =  \n",
    "        # best (lambda1, lambda2) = (0.001, 0.0005)\n",
    "        lamda1 = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 1.2e-1, 1.4e-1, 1.6e-1, 1.8e-1, 2e-1, 2.2e-1, 2.4e-1, 2.6e-1, 2.8e-1, 3e-1, 3.1e-1, 3.2e-1, 3.23e-1, 3.25e-1, 3.27e-1, 3.3e-1, 3.35e-1, 3.5e-1]\n",
    "        lamda2 = [0, 9e-3,7e-3, 6e-3, 3e-3, 1e-2, 2e-2, 5e-2, 8e-2, 1e-1, 1.1e-1, 1.2e-1, 1.3e-1, 1.4e-1, 1.5e-1, 1.6e-1, 1.7e-1, 1.8e-1, 2e-1, 2.1e-1, 2.3e-1, 2.5e-1]\n",
    "        lamda3 = [1e-5,  1e-4, 1e-3,  1e-2, 1e-1, 0, 2e-1,8e-1, 1]\n",
    "        \n",
    "        ## pre augmented data                \n",
    "        m = x.shape[1]\n",
    "        m_ts, n_ts = xts.shape\n",
    "        \n",
    "        #set sequence length of segment in augmented time-series data       \n",
    "        l_ts = 2000   #*** \n",
    "        ts_no = round(m_ts / l_ts)\n",
    "         \n",
    "        # init residual matrix D and segmented residual matrix D\n",
    "        D = []\n",
    "        D_seg = np.zeros([l_ts,n_ts]) \n",
    "                      \n",
    "        # init begin index \n",
    "        idb_ts = 0 \n",
    "               \n",
    "#       split time-series data \n",
    "        for sp in range(ts_no):\n",
    "#             print ('idb_ts:', idb_ts)\n",
    "            temp_ts = xts[idb_ts:(idb_ts + l_ts),:]\n",
    "#             print ('seg_ts:',temp_ts.shape)\n",
    "#             print ('seg_ts:',temp_ts)\n",
    "            \n",
    "            tmp_m = temp_ts.shape[0]              \n",
    "            for cs in range(tmp_m-1):\n",
    "                D_seg[cs,:] = temp_ts[(cs + 1),:] - temp_ts[cs,:]        \n",
    "#             print ('D_seg:',D_seg)\n",
    "#             print ('D_seg:',D_seg.shape)\n",
    "\n",
    "            D.append(D_seg)            \n",
    "            idb_ts = idb_ts + l_ts\n",
    "            \n",
    "#         print ('D:',D)\n",
    "#         print ('D:',len(D))\n",
    "        \n",
    "        # init alpha list and alpha \n",
    "        alps = []\n",
    "        alp = 0\n",
    "                \n",
    "        # init iterations and save parameters combination and corresponding score to list\n",
    "        k = len(lamda1)\n",
    "        f = len(lamda2)\n",
    "        b = len(lamda3)\n",
    "        comb_params_score = []\n",
    "        comb_scores = []\n",
    "        comb_params = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        # init scores list for calculating R^2\n",
    "        scores = []        \n",
    "        score = 0\n",
    "        \n",
    "        # tuning parameters in grid\n",
    "        for u in range(k):\n",
    "            for v in range(f):\n",
    "                for w in range(b):\n",
    "                    \n",
    "                # get argumented time-series segmented data\n",
    "                    # random number for selecting segment randomly\n",
    "                    seg_no = np.random.randint(0,ts_no)\n",
    "#                     print ('seg_no:', seg_no)\n",
    "                    \n",
    "                    # Ω augmented time-series data \n",
    "                    current_D = D[seg_no]   \n",
    "#                     print ('current_D :', current_D )\n",
    "#                     print ('current_D_shape :', current_D.shape )\n",
    "                    \n",
    "                                    \n",
    "                ## lar_lasso → lar_supervisedElasticNet \n",
    "                     # give γ equivalent to alpha, convert only one param to two params  \n",
    "                    alp = lamda1[u] / math.sqrt(1 + lamda2[v]) \n",
    "                                          \n",
    "                   # concat train samples(trainX,trainY) to augmented matrix for augmenting traindata and adding hyperparameter           \n",
    "                      # S1:augmenting trainX and trainY                        \n",
    "                      # calculating time-series data for lambda3 and init identity matrix for lambda 2 and padding 0 for trainY\n",
    "                    current_D = math.sqrt(lamda3[w]) * current_D  \n",
    "                    I = math.sqrt(lamda2[v]) * np.eye(m)\n",
    "                    ctD_m = current_D.shape[0]\n",
    "                    # concate \n",
    "                    z0 = np.zeros([m + ctD_m])\n",
    "                    \n",
    "                     # cat trainX and trainY for augmenting\n",
    "                    trainX = np.concatenate((x, I, current_D), 0)\n",
    "                    trainY = np.concatenate((y, z0), 0)\n",
    "                     # cat trainX and alpha for converting free parameters β implementing “elastic”\n",
    "\n",
    "                    trainX = 1 / math.sqrt(1 + lamda2[v]) *  trainX \n",
    "\n",
    "#                     print ('current_lamda1:', lamda1[u])\n",
    "\n",
    "\n",
    "                    # struct Lar_ElasticNet model using current hyperparameter\n",
    "                    clf = LassoLars(alpha = alp, max_iter = 50)\n",
    "                    # fit current model \n",
    "                    current_model = clf.fit(trainX, trainY)\n",
    "    #                 print ('current_lar_elasticnet:', current_model)\n",
    "                    # Return the coefficient of determination R^2 of the prediction\n",
    "\n",
    "                    ######################*********************####################\n",
    "                    score = current_model.score(x, y, None)\n",
    "                    # save score to list\n",
    "                    scores.append(score)\n",
    "#                     print ('current_score:', score)\n",
    "#                     print ('---------------------------------------')\n",
    "\n",
    "                    # save combination para list\n",
    "                    comb_params_score.append(np.array([lamda1[u], lamda2[v] ,lamda3[w], score]))\n",
    "\n",
    "                    # save all locations and scores(lambda1, lambda2, lambda3)\n",
    "                    comb_scores.append(np.array([u, v, w, score]))\n",
    "                    comb_params.append((u, v, w))\n",
    "\n",
    "                    # save current alpha\n",
    "                    alps.append(alp)\n",
    "                \n",
    "        # list → numpy\n",
    "        scores = np.array(scores)\n",
    "        # Returns the index that would sort an array(default: ascending order)\n",
    "        idx = np.argsort(scores)\n",
    "        \n",
    "        # print best score \n",
    "        best_score = scores[idx[-1]]\n",
    "        print ('best_score:', best_score)\n",
    "        \n",
    "        # print best lambda param_group\n",
    "        best_params_score = comb_params_score[idx[-1]]\n",
    "#         print ('best_params_score:', best_params_score)\n",
    "        print ('-----------------------------------------')\n",
    "        \n",
    "        # select highest score and save corresponding location(lamda1, lamda2)\n",
    "        opt['alpha'] = alps[idx[-1]]\n",
    "        opt['combine_params'] = comb_params[idx[-1]] \n",
    "        return opt, best_params_score, comb_params_score,comb_scores\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def evaluate(self, pred_y, true_y, metrics):\n",
    "        pred_y = pred_y.reshape([-1])\n",
    "        true_y = true_y.reshape([-1])\n",
    "        metrics_num = len(metrics)\n",
    "        results = np.zeros([metrics_num])\n",
    "        for i,metric in enumerate(metrics):\n",
    "            if metric == 'rmse':\n",
    "                results[i] = np.sqrt(np.mean(np.power(pred_y - true_y,2)))\n",
    "            elif metric == 'mape':\n",
    "                results[i] = np.mean(np.abs(true_y - pred_y) / true_y)*100\n",
    "            elif metric == 'correlation':\n",
    "                results[i] = np.corrcoef(pred_y, true_y)[0,1]\n",
    "            elif metric == 'wi':\n",
    "                results[i] = np.sum(np.power(true_y - pred_y, 2)) / np.sum(np.power(np.abs(pred_y - np.mean(true_y)) + np.abs(true_y-np.mean(true_y)), 2))\n",
    "        return results      \n",
    "          \n",
    "        \n",
    "    def run_experiments(self, methods, experiments, repeat_num, metrics):\n",
    "        # dic type\n",
    "        results = {}\n",
    "        for exp_name in experiments.keys():\n",
    "            # exp_name is dict_keys type\n",
    "            exp = experiments[exp_name]\n",
    "            train_time, test_time = exp['times']\n",
    "            evaluation = np.zeros([repeat_num, len(exp['lag_time']), len(exp['clustering']), len(exp['normalize']), len(methods), len(metrics)])\n",
    "            print ('repeat_num:',repeat_num)\n",
    "                        \n",
    "            for r in range(repeat_num):\n",
    "                for i,lag_time in enumerate(exp['lag_time']):\n",
    "                    for j,clustering in enumerate(exp['clustering']):\n",
    "                        for k,normalize in enumerate(exp['normalize']):\n",
    "                            \n",
    "                            # time-series data\n",
    "                            self.source.attr2source(train_time, \n",
    "                                                    normalize,\n",
    "                                                    0, \n",
    "                                                    lag_time,\n",
    "                                                    data_type='time-series')                            \n",
    "                            \n",
    "                            # general training data\n",
    "                            self.source.attr2source(train_time, \n",
    "                                                    normalize,\n",
    "                                                    clustering, \n",
    "                                                    lag_time,\n",
    "                                                    data_type='train')\n",
    "                            # general testing data\n",
    "                            self.source.attr2source(test_time,\n",
    "                                                     normalize, \n",
    "                                                     clustering, \n",
    "                                                     lag_time,\n",
    "                                                     data_type='test')\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            ensemble_y = 0\n",
    "                            for t, method in enumerate(methods):\n",
    "                                # baseline model\n",
    "                                if method == 'lasso':\n",
    "                                    model = self.build_model(method, self.source)\n",
    "                                    model = model.fit(self.source.train_x, self.source.train_y)\n",
    "                                    predict_y = model.predict(self.source.test_x)                               \n",
    "                                    \n",
    "                                else:                                \n",
    "                                # ablation study on validation\n",
    "                                    if method == 'no_timeSeries_Tenlar':\n",
    "                                        \n",
    "                                        opt, best_params_score, model,comb_params_score ,comb_scores = self.build_model(method, self.source)                                \n",
    "                                        model = model.fit(self.source.train_x, self.source.train_y)\n",
    "                                        predict_y = model.predict(self.source.test_x)                                                                                                    \n",
    "                                        \n",
    "                                \n",
    "                                    else:\n",
    "  \n",
    "                                        train_X = np.concatenate((self.source.train_x, self.source.ts_x), 0)\n",
    "                                        train_Y = np.concatenate((self.source.train_y, self.source.ts_y), 0)\n",
    "#                             \n",
    "                                        model = model.fit(train_X, train_Y)\n",
    "                                        predict_y = model.predict(self.source.test_x)\n",
    "               \n",
    "                                evaluation[r, i, j, k, t, :] = self.evaluate(predict_y, self.source.test_y, metrics)\n",
    "                                print('exp_name={}, lag_time={}, normalize={}, clustering={}, method={} :{}'.format(\n",
    "                                    exp_name, lag_time, normalize, clustering, method, evaluation[r, i, j, k, t, :]))\n",
    "                                \n",
    "            # save results as a dictionary \n",
    "            np.save('result/{}.npy'.format(exp_name), evaluation)            \n",
    "#             results[exp_name] = evaluation\n",
    "\n",
    "\n",
    "    def decimal2round2(self, results):\n",
    "        sh = results.shape\n",
    "        fraction = results.reshape(-1)\n",
    "        for m in range(len(fraction)):\n",
    "            fraction[m] = round(fraction[m],8)\n",
    "        fractions = fraction.reshape(sh)\n",
    "#         print ('fractions_shape',fractions.shape)\n",
    "        return fractions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat_num: 5\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.12186691 6.14392507 0.91994488 0.15311998]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.12186691 6.14392507 0.91994488 0.15311998]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.12186691 6.14392507 0.91994488 0.15311998]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_IM_Tenlar :[3.12186691 6.14392507 0.91994488 0.15311998]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=full_model :[3.12186691 6.14392507 0.91994488 0.15311998]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=lasso :[3.11780566 6.14548401 0.91908018 0.1533114 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.23625763 6.259006   0.91502384 0.15911526]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.23625763 6.259006   0.91502384 0.15911526]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.23625763 6.259006   0.91502384 0.15911526]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_IM_Tenlar :[3.23625763 6.259006   0.91502384 0.15911526]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=full_model :[3.23625763 6.259006   0.91502384 0.15911526]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=lasso :[3.23085966 6.25230204 0.91513886 0.15884765]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.05629012 6.02792216 0.93217369 0.14263188]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.05629012 6.02792216 0.93217369 0.14263188]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.05629012 6.02792216 0.93217369 0.14263188]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_IM_Tenlar :[3.05629012 6.02792216 0.93217369 0.14263188]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=full_model :[3.05629012 6.02792216 0.93217369 0.14263188]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=lasso :[3.08886303 6.0500505  0.92600887 0.14567777]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.0085142  5.83740478 0.93234627 0.1358171 ]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.0085142  5.83740478 0.93234627 0.1358171 ]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.0085142  5.83740478 0.93234627 0.1358171 ]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_IM_Tenlar :[3.0085142  5.83740478 0.93234627 0.1358171 ]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=full_model :[3.0085142  5.83740478 0.93234627 0.1358171 ]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=lasso :[2.95478072 5.76063007 0.9324041  0.13325629]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.76684693 5.3695195  0.9423882  0.12246783]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.76684693 5.3695195  0.9423882  0.12246783]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.76684693 5.3695195  0.9423882  0.12246783]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_IM_Tenlar :[2.76684693 5.3695195  0.9423882  0.12246783]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=full_model :[2.76684693 5.3695195  0.9423882  0.12246783]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=lasso :[2.7994142  5.41272058 0.93905236 0.12477689]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.93380843 5.8306413  0.93608599 0.13712304]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.93380843 5.8306413  0.93608599 0.13712304]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.93380843 5.8306413  0.93608599 0.13712304]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_IM_Tenlar :[2.93380843 5.8306413  0.93608599 0.13712304]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=full_model :[2.93380843 5.8306413  0.93608599 0.13712304]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=lasso :[2.93542381 5.82584024 0.93576425 0.13730381]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.15298534 6.21765587 0.91110677 0.15410034]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.15298534 6.21765587 0.91110677 0.15410034]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.15298534 6.21765587 0.91110677 0.15410034]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_IM_Tenlar :[3.15298534 6.21765587 0.91110677 0.15410034]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=full_model :[3.15298534 6.21765587 0.91110677 0.15410034]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=lasso :[3.13865951 6.19598489 0.91226012 0.15322576]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.29011015 6.45701479 0.91610245 0.16965539]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.29011015 6.45701479 0.91610245 0.16965539]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.29011015 6.45701479 0.91610245 0.16965539]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_IM_Tenlar :[3.29011015 6.45701479 0.91610245 0.16965539]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=full_model :[3.29011015 6.45701479 0.91610245 0.16965539]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=lasso :[3.26796161 6.41682762 0.91643776 0.16864929]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.77582692 5.37976318 0.93398014 0.12115842]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.77582692 5.37976318 0.93398014 0.12115842]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.77582692 5.37976318 0.93398014 0.12115842]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_IM_Tenlar :[2.77582692 5.37976318 0.93398014 0.12115842]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=full_model :[2.77582692 5.37976318 0.93398014 0.12115842]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=lasso :[2.74422149 5.315404   0.93476537 0.11949744]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.95915737 5.7229393  0.92328506 0.13742556]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.95915737 5.7229393  0.92328506 0.13742556]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.95915737 5.7229393  0.92328506 0.13742556]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_IM_Tenlar :[2.95915737 5.7229393  0.92328506 0.13742556]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=full_model :[2.95915737 5.7229393  0.92328506 0.13742556]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=lasso :[2.93307071 5.62523594 0.91981601 0.13744248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.1698744  6.12708055 0.92495678 0.15025098]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.1698744  6.12708055 0.92495678 0.15025098]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.1698744  6.12708055 0.92495678 0.15025098]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_IM_Tenlar :[3.1698744  6.12708055 0.92495678 0.15025098]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=full_model :[3.1698744  6.12708055 0.92495678 0.15025098]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=lasso :[3.22142256 6.2252529  0.92311067 0.15302828]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.28290737 6.51225605 0.92296096 0.16740525]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.28290737 6.51225605 0.92296096 0.16740525]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.28290737 6.51225605 0.92296096 0.16740525]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_IM_Tenlar :[3.28290737 6.51225605 0.92296096 0.16740525]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=full_model :[3.28290737 6.51225605 0.92296096 0.16740525]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=lasso :[3.22713758 6.41006477 0.92435072 0.16479101]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.87283244 5.44315659 0.91341026 0.13722931]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.87283244 5.44315659 0.91341026 0.13722931]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.87283244 5.44315659 0.91341026 0.13722931]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_IM_Tenlar :[2.87283244 5.44315659 0.91341026 0.13722931]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=full_model :[2.87283244 5.44315659 0.91341026 0.13722931]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=lasso :[2.87397202 5.4290564  0.91334443 0.13732729]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.87347151 5.5981982  0.935026   0.13141663]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.87347151 5.5981982  0.935026   0.13141663]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.87347151 5.5981982  0.935026   0.13141663]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_IM_Tenlar :[2.87347151 5.5981982  0.935026   0.13141663]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=full_model :[2.87347151 5.5981982  0.935026   0.13141663]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=lasso :[2.86778893 5.57574404 0.93426192 0.1313882 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.25170689 6.36829564 0.92856671 0.15713103]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.25170689 6.36829564 0.92856671 0.15713103]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.25170689 6.36829564 0.92856671 0.15713103]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_IM_Tenlar :[3.25170689 6.36829564 0.92856671 0.15713103]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=full_model :[3.25170689 6.36829564 0.92856671 0.15713103]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=lasso :[3.23700569 6.34327575 0.92964074 0.15624118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.87037456 5.70106089 0.94000447 0.12593577]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.87037456 5.70106089 0.94000447 0.12593577]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.87037456 5.70106089 0.94000447 0.12593577]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_IM_Tenlar :[2.87037456 5.70106089 0.94000447 0.12593577]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=full_model :[2.87037456 5.70106089 0.94000447 0.12593577]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=lasso :[2.86554056 5.69080012 0.9387717  0.12611924]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.99973335 5.99104483 0.94343445 0.13262597]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.99973335 5.99104483 0.94343445 0.13262597]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.99973335 5.99104483 0.94343445 0.13262597]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_IM_Tenlar :[2.99973335 5.99104483 0.94343445 0.13262597]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=full_model :[2.99973335 5.99104483 0.94343445 0.13262597]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=lasso :[2.98052113 5.942495   0.94202478 0.13225608]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.07799657 6.08541441 0.93776195 0.15290307]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.07799657 6.08541441 0.93776195 0.15290307]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.07799657 6.08541441 0.93776195 0.15290307]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_IM_Tenlar :[3.07799657 6.08541441 0.93776195 0.15290307]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=full_model :[3.07799657 6.08541441 0.93776195 0.15290307]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=lasso :[3.04245836 6.04652548 0.93737348 0.15149074]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.29278577 6.4468799  0.92338291 0.16418138]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.29278577 6.4468799  0.92338291 0.16418138]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.29278577 6.4468799  0.92338291 0.16418138]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_IM_Tenlar :[3.29278577 6.4468799  0.92338291 0.16418138]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=full_model :[3.29278577 6.4468799  0.92338291 0.16418138]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=lasso :[3.27853374 6.42259412 0.9243145  0.16334361]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.96842153 5.82759866 0.93221106 0.13554792]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.96842153 5.82759866 0.93221106 0.13554792]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.96842153 5.82759866 0.93221106 0.13554792]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_IM_Tenlar :[2.96842153 5.82759866 0.93221106 0.13554792]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=full_model :[2.96842153 5.82759866 0.93221106 0.13554792]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=lasso :[2.92544208 5.75033059 0.93276973 0.13356445]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.76624716 5.3933916  0.93463355 0.13187771]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.76624716 5.3933916  0.93463355 0.13187771]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.76624716 5.3933916  0.93463355 0.13187771]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=no_IM_Tenlar :[2.76624716 5.3933916  0.93463355 0.13187771]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=full_model :[2.76624716 5.3933916  0.93463355 0.13187771]\n",
      "exp_name=spring, lag_time=8, normalize=1, clustering=0, method=lasso :[2.74442986 5.36056402 0.93558061 0.13062106]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.13853015 6.1509399  0.92207714 0.14812051]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.13853015 6.1509399  0.92207714 0.14812051]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.13853015 6.1509399  0.92207714 0.14812051]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=no_IM_Tenlar :[3.13853015 6.1509399  0.92207714 0.14812051]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=full_model :[3.13853015 6.1509399  0.92207714 0.14812051]\n",
      "exp_name=spring, lag_time=10, normalize=1, clustering=0, method=lasso :[3.11568778 6.09061414 0.92365359 0.14663869]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.92090296 5.73504708 0.93238113 0.14241162]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.92090296 5.73504708 0.93238113 0.14241162]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.92090296 5.73504708 0.93238113 0.14241162]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=no_IM_Tenlar :[2.92090296 5.73504708 0.93238113 0.14241162]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=full_model :[2.92090296 5.73504708 0.93238113 0.14241162]\n",
      "exp_name=spring, lag_time=12, normalize=1, clustering=0, method=lasso :[2.893337   5.6597643  0.93055239 0.1418418 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.04984281 6.03733652 0.92471666 0.14822162]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.04984281 6.03733652 0.92471666 0.14822162]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.04984281 6.03733652 0.92471666 0.14822162]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=no_IM_Tenlar :[3.04984281 6.03733652 0.92471666 0.14822162]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=full_model :[3.04984281 6.03733652 0.92471666 0.14822162]\n",
      "exp_name=spring, lag_time=14, normalize=1, clustering=0, method=lasso :[3.06374855 6.07551876 0.92287699 0.14933437]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[3.14210451 6.1841162  0.92069271 0.15012995]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[3.14210451 6.1841162  0.92069271 0.15012995]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[3.14210451 6.1841162  0.92069271 0.15012995]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=no_IM_Tenlar :[3.14210451 6.1841162  0.92069271 0.15012995]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=full_model :[3.14210451 6.1841162  0.92069271 0.15012995]\n",
      "exp_name=spring, lag_time=2, normalize=1, clustering=0, method=lasso :[3.13146945 6.17058953 0.92100754 0.14967501]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_timeSeries_Tenlar :[2.90618558 5.73704647 0.93048036 0.12939913]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_l3Norm_Tenlar :[2.90618558 5.73704647 0.93048036 0.12939913]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_l2Norm_Tenlar :[2.90618558 5.73704647 0.93048036 0.12939913]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=no_IM_Tenlar :[2.90618558 5.73704647 0.93048036 0.12939913]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=full_model :[2.90618558 5.73704647 0.93048036 0.12939913]\n",
      "exp_name=spring, lag_time=3, normalize=1, clustering=0, method=lasso :[2.87003402 5.66254738 0.93094677 0.12761109]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/yqliu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a6a4b1ba47f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mconfig_ablation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                   \u001b[0mconfig_ablation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                   config_ablation.metrics)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-181dec7a6b87>\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(self, methods, experiments, repeat_num, metrics)\u001b[0m\n\u001b[1;32m    532\u001b[0m                                     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_timeSeries_Tenlar'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m                                         \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomb_params_score\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcomb_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m                                         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                                         \u001b[0mpredict_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-181dec7a6b87>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self, method, source)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'no_timeSeries_Tenlar'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb_params_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_no_timeSeries_Tenlar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0malp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLassoLars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-181dec7a6b87>\u001b[0m in \u001b[0;36mcv_no_timeSeries_Tenlar\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLassoLars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mcurrent_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, Xy)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         self._fit(X, y, max_iter=max_iter, alpha=alpha, fit_path=self.fit_path,\n\u001b[0;32m--> 709\u001b[0;31m                   Xy=Xy)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_iter, alpha, fit_path, Xy)\u001b[0m\n\u001b[1;32m    646\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m                     return_n_iter=True, positive=self.positive)\n\u001b[0m\u001b[1;32m    649\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py\u001b[0m in \u001b[0;36mlars_path\u001b[0;34m(X, y, Xy, Gram, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mC_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mC_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mC_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCov\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mC_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \"\"\"\n\u001b[0;32m-> 1004\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir(config_ablation.path)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "m = Water(config_ablation.excel_files)\n",
    "m.run_experiments(config_ablation.methods, \n",
    "                  config_ablation.experiments,\n",
    "                  config_ablation.repeat_num,\n",
    "                  config_ablation.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## monitor for paper(graphs + tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import config_final\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "# change work content to specific path(/mnt/pami/yqliu/water/)\n",
    "os.chdir(config_final.path)\n",
    "\n",
    "def write_optimalParams(experiments, repeat_num):\n",
    "    for exp_name in experiments.keys():\n",
    "        # exp_name is dict_keys type\n",
    "        exp = experiments[exp_name]\n",
    "        for r in range(repeat_num):\n",
    "            for i,lag_time in enumerate(exp['lag_time']):\n",
    "                f = open(osp.join('lar_semisup_elasticnet_params','{}-{}-{}-{}-params.txt'.format(exp_name, r, lag_time, 'semi-supervised_lar_elasticnet')), 'r')\n",
    "\n",
    "                # results with string type\n",
    "                aa = f.read()\n",
    "                \n",
    "                # convert to dic type\n",
    "#                 hyperparams_lar_elasticnet = exec(a)\n",
    "\n",
    "                print ('{}-{}-{}-{}-params.txt'.format(exp_name, r, lag_time, 'semi-supervised_lar_elasticnet'), aa )\n",
    "\n",
    "    f.close()\n",
    "                       \n",
    "# calling\n",
    "write_optimalParams(config_final.experiments,config_final.repeat_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All year prediction and save .txt to LaTeX table\n",
    "os.chdir(config_final.path)\n",
    "\n",
    "# import  all_year record and return a ndnumpy\n",
    "result = np.load('result/old2new.npy')\n",
    "\n",
    "# remove redundant dimension of length 1\n",
    "# ***0th is repeat_num（e.g. all year twice = 2）shape=(rp_n.,lag,nor.,clu.,methd.,metric.)\n",
    "\n",
    "## calculate mean results on every model for 4 metrics\n",
    "mean_result = np.mean(result.squeeze(), 0)\n",
    "\n",
    "## calculate standard results on every model for 4 metrics\n",
    "std_result = np.std(result.squeeze(), 0)\n",
    "\n",
    "\n",
    "# print all original results split mean and standard\n",
    "print ('mean_result_original:', mean_result)\n",
    "\n",
    "print ('std_result_original:', std_result)\n",
    "\n",
    "# rounding\n",
    "mean_result = m.decimal2round2(mean_result)\n",
    "std_result = m.decimal2round2(std_result)\n",
    "\n",
    "# print all rounding results split mean and standard\n",
    "print ('mean_result_decimal:', mean_result )\n",
    "print ('std_result_decimal:', std_result )\n",
    "\n",
    "file_name = 'table_old2new.txt'\n",
    "# write to result to 'f'\n",
    "f = open(file_name,'w')\n",
    "\n",
    "# write a format such as ' & & {methods}'\n",
    "f.write(' &')\n",
    "for method in config_final.methods:\n",
    "    f.write(' & {}'.format(method))\n",
    "\n",
    "# write a format such as  '\\\\\\\\ \\\\hline \\n'\n",
    "f.write(' \\\\\\\\ \\\\hline \\n')\n",
    "\n",
    "\n",
    "for i,metric in enumerate(config_final.metrics):\n",
    "    f.write(' & {}'.format(metric))\n",
    "    for j,method in enumerate(config_final.methods):\n",
    "        if metric == 'wi':\n",
    "            mean_result[j][i] *= 100\n",
    "            std_result[j][i] *= 100\n",
    "        # split mean('rmse', 'mape', 'correlation', 'wi') and std to 2 tables   \n",
    "        # result : mean + std\n",
    "        f.write(' & {}$\\\\pm${}'.format(mean_result[j][i], std_result[j][i]))\n",
    "    if i == len(config_final.metrics)-1:\n",
    "        f.write(' \\\\\\\\ \\\\hline \\\\hline \\n')\n",
    "    else:\n",
    "        f.write(' \\\\\\\\ \\\\hline \\n')\n",
    "f.close()\n",
    "\n",
    "content = open(file_name, 'r').readlines()\n",
    "print(content)\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Format：\n",
    "\n",
    "rmse:lar_elasticNet     /xgboost       /   lightgbm         /    mlr     /     ridge_regression   /     lasso  /random_forest  /  mlp  /  nn  /  ensemble\n",
    "     mean:              mean:1.64±0.07   mean:1.91±0.11    mean:1.48±0.07     mean:1.43$±0.05    mean:1.42±0.05   ...\n",
    "     \n",
    "mape:...\n",
    "\n",
    "correlation:...\n",
    "\n",
    "wi:...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal prediction\n",
    "file_name = 'table_seasonal.txt'\n",
    "f = open(file_name,'w')\n",
    "f.write(' &')\n",
    "for method in config_final.methods:\n",
    "    f.write(' & {}'.format(method))\n",
    "f.write(' \\\\\\\\ \\\\hline \\n')\n",
    "flag = 0\n",
    "for season in ['spring', 'summer', 'autumn', 'winter']:\n",
    "    result = np.load(osp.join('result', '{}.npy'.format(season))).squeeze()\n",
    "    print ('mean_result_origin:',result.shape)\n",
    "    \n",
    "    if season == 'autumn' or season == 'winter':\n",
    "        \n",
    "        # ***select the best result lag as results \n",
    "        result = result[:,1,:,:]\n",
    "#     flag = flag +1 \n",
    "#     print ('flag:',flag)\n",
    "#         print ('result_au:', result.shape)\n",
    "\n",
    "    mean_result = np.mean(result, 0)\n",
    "    std_result = np.std(result, 0) \n",
    "    print ('mean_result_shape:', mean_result )\n",
    "    print ('std_result_shape:', std_result)\n",
    "    \n",
    "    \n",
    "    # select two decimal places\n",
    "    mean_result = m.decimal2round2(mean_result)\n",
    "    std_result = m.decimal2round2(std_result)\n",
    "#     print ('mean_result_shape2:', mean_result.shape)\n",
    "    \n",
    "    f.write('{}'.format(season))\n",
    "    for i,metric in enumerate(config_final.metrics):\n",
    "        f.write(' & {}'.format(metric))\n",
    "        for j,method in enumerate(config_final.methods):\n",
    "            if metric == 'wi':\n",
    "                mean_result[j][i] *= 100\n",
    "                std_result[j][i] *= 100\n",
    "            f.write(' & {}$\\\\pm${}'.format(mean_result[j][i], std_result[j][i]))\n",
    "        if i == len(config_final.metrics)-1:\n",
    "            f.write(' \\\\\\\\ \\\\hline \\\\hline \\n')\n",
    "        else:\n",
    "            f.write(' \\\\\\\\ \\\\hline \\n')\n",
    "f.close()\n",
    "\n",
    "content = open(file_name, 'r').readlines()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot figure about parameters influence of ElasticNet using Least-Angle Regression(lar_elasticnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 3D figure toolkit\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "os.chdir(config_final.path)\n",
    "results = np.load(osp.join('lar_elasticnet_3d','{}-{}-{}-{}-scores.npy'.format('spring', 0, 8, 'lar_elasticnet')))\n",
    "\n",
    "# print ('results_shape:', results.shape)\n",
    "        \n",
    "# print ('results:', results)\n",
    "           \n",
    "f, v = results.shape\n",
    "\n",
    "# assign X , Y and Z\n",
    "\n",
    "X = results[:,0]\n",
    "Y = results[:,1]\n",
    "Z = results[:,2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## plot 3D surface diagram\n",
    "\n",
    "fig = plt.figure(figsize = (18,8))\n",
    "\n",
    "# Module containing Axes3D, an object which can plot 3D objects on a 2D matplotlib figure\n",
    "# ax is a Axes3D instance\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "\n",
    "\n",
    "Z = results[:,2].T\n",
    "Z_list = []\n",
    "for i in range(f):\n",
    "    Z_list.append(Z)\n",
    "    \n",
    "\n",
    "Z_scores = np.concatenate(Z_list) \n",
    "Z_scores = Z_scores.reshape(f,f)\n",
    "\n",
    "ax.set_title(\"Parameters-Perturbation Surface Diagram on LAR_ElasticNet\")\n",
    "ax.set_xlabel(\"lambda1\")\n",
    "ax.set_ylabel(\"lambda2\")\n",
    "ax.set_zlabel(\"R^2-Score\")\n",
    "\n",
    "# print ('z_scores:',Z_scores)\n",
    "# print ('z_scores_shape:',Z_scores.shape)\n",
    "\n",
    "\n",
    "ax.plot_surface(X, Y, Z_scores,  cmap=plt.cm.get_cmap('rainbow'))\n",
    "# ax.legend()\n",
    "os.chdir('/home/yqliu/Yiwei_water/results')\n",
    "fig.savefig('Parameters-Perturbation pic2 on LAR_ElasticNet.pdf' , bbox_inches='tight', pad_inches=0.2, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot figure about effect of previous aluminum doses in autumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "styles = ['r*--','b*--', 'm>-', 'y<-', 'c^-', 'ms-', 'yv-', 'b+-', 'gh-','k-', 'c*--']\n",
    "methods_fmt = ['Semi-Supervised_LAR_ElasticNet', 'LAR_ElasticNet', 'Lasso','XGBoost','LightGBM', 'MLR', 'Ridge_Regression', 'Random_Forest', 'MLP','NN', 'Ensemble']\n",
    "\n",
    "os.chdir(config_final.path)\n",
    "\n",
    "result = np.load(osp.join('result', 'spring.npy')).squeeze()\n",
    "\n",
    "# print ('results:', results)\n",
    "\n",
    "# mean experiment times\n",
    "results = result.mean(0)\n",
    "\n",
    "# result shape = [lag_time, methods]→RMSE\n",
    "rmse_results = results[:, :, 0]\n",
    "# result shape = [lag_time, methods]→Correlation\n",
    "correlation_results = results[:, :, 2]\n",
    "\n",
    "# create a new figure instance[Figure], figsize is width, height(in inches) of Figure\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "\n",
    "# dding sub-plot instance(Axes) and its coordinate axis [left, bottom, width, height]\n",
    "ax1 = fig.add_axes([0.1, 0.1, 1.2, 1.2])\n",
    "ax2 = fig.add_axes([0.2, 0.7, 0.5, 0.5])\n",
    "\n",
    "# ploting Figure\n",
    "for j,method in enumerate(methods_fmt):\n",
    "\n",
    "    # 6 lags for same method to plot x:lags  y:RMSE\n",
    "#         [2,4,6,8,10,12]\n",
    "    ax1.plot(np.array([2,4,6,8,12,14]),rmse_results[:, j], styles[j],linewidth = 2.5, label=method)\n",
    "    ax2.plot(np.array([2,4,6,8,12,14]),correlation_results[:, j], styles[j], label=method)\n",
    "    \n",
    "# set grid    \n",
    "# ax1.grid()\n",
    "# ax2.grid()\n",
    "# set text and axis of Figure\n",
    "# ax1\n",
    "ax1.set_title('The Effect of Previous Aluminum Doses in Autumn', fontsize=14)\n",
    "ax1.set_xlim(-1,15)\n",
    "# ax1.xticks(np.linspace(-np.pi,np.pi,20))\n",
    "ax1.set_ylim(0,3)\n",
    "ax1.set_xlabel('The Number of Previous Timesteps(t)',fontsize=14)\n",
    "ax1.set_ylabel('RMSE',fontsize=14)\n",
    "\n",
    "#ax2\n",
    "ax2.set_ylabel('Correlation',fontsize=14)\n",
    "ax2.set_xlim(-1,15)\n",
    "ax2.set_ylim(-0.5,3)\n",
    "\n",
    "ax1.legend(loc = 'upper right')\n",
    "\n",
    "# save\n",
    "os.chdir('/home/yqliu/Yiwei_water/results')\n",
    "fig.savefig('PAD in Autumn.pdf', bbox_inches='tight', pad_inches=0.2, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot figure about effect of previous aluminum doses in winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(9,7))\n",
    "styles = ['r*--','b*--', 'm>-', 'y<-', 'c^-', 'ms-', 'yv-', 'b+-', 'gh-','k-', 'c*--']\n",
    "\n",
    "methods_fmt = ['LAR_ElasticNet', 'Lasso','XGBoost','LightGBM', 'MLR', 'Ridge_Regression', 'Random_Forest', 'MLP','NN', 'Ensemble']\n",
    "\n",
    "os.chdir(config_final.path)\n",
    "\n",
    "result = np.load(osp.join('result', 'winter.npy')).squeeze()\n",
    "\n",
    "# mean experiment times\n",
    "results = result.mean(0)\n",
    "\n",
    "# result shape = [lag_time, methods]→RMSE\n",
    "rmse_results = results[:, :, 0]\n",
    "# result shape = [lag_time, mehtods]→Wi\n",
    "wi_results = results[:, :, 3]\n",
    "\n",
    "# create a new figure instance[Figure], figsize is width, height(in inches) of Figure\n",
    "fig = plt.figure(figsize = (9, 7))\n",
    "\n",
    "# dding sub-plot instance(Axes) and its coordinate axis [left, bottom, width, height]\n",
    "ax1 = fig.add_axes([0.1, 0.1, 1.2, 1.2])\n",
    "ax2 = fig.add_axes([0.2, 0.7, 0.5, 0.5])\n",
    "\n",
    "# ploting Figure\n",
    "for j,method in enumerate(methods_fmt):\n",
    "\n",
    "    # 6 lags for same method to plot x:lags  y:RMSE\n",
    "#         [2,4,6,8,10,12]\n",
    "    ax1.plot(np.array([2,4,6,8,10,12]),rmse_results[:, j], styles[j], linewidth = 2.5, label=method)\n",
    "    ax2.plot(np.array([2,4,6,8,10,12]),wi_results[:, j], styles[j], label=method)\n",
    "    \n",
    "# set grid    \n",
    "# ax1.grid()\n",
    "# ax2.grid()\n",
    "# set text and axis of Figure\n",
    "# ax1\n",
    "ax1.set_title('The Effect of Previous Aluminum Doses in Winter', fontsize=14)\n",
    "ax1.set_xlim(-1,13)\n",
    "ax1.set_ylim(0,8)\n",
    "ax1.set_xlabel('The Number of Previous Timesteps(t)',fontsize=14)\n",
    "ax1.set_ylabel('RMSE',fontsize=14)\n",
    "\n",
    "#ax2\n",
    "ax2.set_ylabel('WI',fontsize=14)\n",
    "ax2.set_xlim(-1,13)\n",
    "ax2.set_ylim(-0.5,2)\n",
    "\n",
    "ax1.legend(loc = 'upper right')\n",
    "\n",
    "# save\n",
    "os.chdir('/home/yqliu/Yiwei_water/results')\n",
    "fig.savefig('PAD in water.pdf' , bbox_inches='tight', pad_inches=0.2, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot figure about scatterplot of measured/calculated coagulant dosage in training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all random result data\n",
    "GT_test, GT_train, predicted_results_test, predicted_results_train = m.specify_experiments(config_final.methods, config_final.experiments)\n",
    "print (\"loading completely...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "  \n",
    "# print ('predicted_results_test_shape:', predicted_results_test.shape) \n",
    "# print ('predicted_results_test:',predicted_results_test)\n",
    "    \n",
    "# set sample number\n",
    "sample_number = 150 \n",
    "L = np.arange(sample_number)                                                                                           \n",
    "                                                                                           \n",
    "# set random sample_id                                                                                            \n",
    "sample_id = np.random.randint(0,(1000 - sample_number + 1) )\n",
    "\n",
    "print ('sample_id:',sample_id)\n",
    "                                                                                           \n",
    "fig = plt.figure(figsize=(9,6))\n",
    "styles = ['r-','b-', 'k-', 'y-', 'c-', 'm-', 'y-', 'b-', 'g-','c--']\n",
    "methods_fmt = ['LAR_ElasticNet', 'Lasso','XGBoost','LightGBM', 'MLR', 'Ridge_Regression', 'Random_Forest', 'MLP','NN', 'Ensemble']\n",
    "\n",
    "os.chdir(config_final.path)\n",
    "\n",
    "\n",
    "# create a new figure instance[Figure], figsize is width, height(in inches) of Figure\n",
    "fig = plt.figure(figsize = (13, 7))\n",
    "\n",
    "# adding sub-plot instance(Axes) and its coordinate axis [left, bottom, width, height]\n",
    "ax1 = fig.add_axes([0.1, 0.1, 1.2, 1.2])\n",
    "ax2 = fig.add_axes([0.2, 0.77, 0.5, 0.5])\n",
    "\n",
    "\n",
    "# vv = predicted_results_test[j, sample_id:(sample_id+sample_number)]\n",
    "# print ('vv_shape:',vv.shape)\n",
    "\n",
    "# ploting Figure\n",
    "for j,method in enumerate(methods_fmt):\n",
    "\n",
    "    # use random predicted result data for training and testing\n",
    "    ax1.plot(L,predicted_results_test[j, sample_id:(sample_id+sample_number)], styles[j], linewidth = 1, label=method)                                                                                                                                                                                      \n",
    "    ax2.plot(L,predicted_results_train[j, sample_id:(sample_id+sample_number)], styles[j], linewidth = 1, label=method)\n",
    "\n",
    "# use random GT result data for training and testing\n",
    "ax1.plot(L,GT_test[sample_id:(sample_id+sample_number)], 'k:', linewidth = 1.5, label='optimal')                                                                                                                                                                                      \n",
    "ax2.plot(L,GT_train[sample_id:(sample_id+sample_number)], 'k:', linewidth = 1.5, label='optimal')                                                                                                                                                                                      \n",
    "                                                                                           \n",
    "\n",
    "                                                                                           \n",
    "# set grid    \n",
    "# ax1.grid()\n",
    "# ax2.grid()\n",
    "# set text and axis of Figure\n",
    "# ax1\n",
    "ax1.set_title('The Scatterplot of Measured/Calculated Coagulant Doses in Traing and Testing', fontsize=14)\n",
    "ax1.set_xlim(-1,160)\n",
    "ax1.set_ylim(20,80)\n",
    "ax1.set_xlabel('N-th Sample(Testing)',fontsize=14)\n",
    "ax1.set_ylabel('Coagulant Dosage(mg/L)',fontsize=14)\n",
    "\n",
    "#ax2\n",
    "ax2.set_xlabel('N-th Sample(Training)',fontsize=14)                                                                                           \n",
    "ax2.set_xlim(-1,160)\n",
    "ax2.set_ylim(20,80)\n",
    "\n",
    "ax1.legend(loc = 'upper right')\n",
    "\n",
    "# save\n",
    "os.chdir('/home/yqliu/Yiwei_water/results')\n",
    "fig.savefig('Measured and calculated CD_pic.pdf', bbox_inches='tight', pad_inches=0.2, dpi=300)\n",
    "# plt.savefig('previous.png',bbox_inches='tight', pad_inches=0.2, dpi = 300)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot histogram of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get whole data(15.1.1-17.1.1) and non-normalized\n",
    "os.chdir(config_final.path)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "m = Water(config_final.excel_files)\n",
    "m.source.attr2source([('2015-01-01 00:00:00','2017-01-01 00:00:00')], 0, 0, 3, 'time-series')\n",
    "dataset_all = m.source.all_x\n",
    "print ('dataset_all_shape:',dataset_all.shape)\n",
    "label_all = m.source.all_y\n",
    "print ('label_all_shape:',label_all.shape)\n",
    "\n",
    "print (\"loading completely...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(18,14))\n",
    "plt.title('Histogram of features in the whole dataset')\n",
    "\n",
    "## plot first feature[RW-Nitrite]\n",
    "\n",
    "#  subplot[nrows, ncols,index], describing the position of the subplot, index starts at 1 in the upper left corner and increases to the right\n",
    "axes = plt.subplot(3,3,1)\n",
    "\n",
    "# input firest feature and set bins equivalent to (20+1)\n",
    "plt.hist(dataset_all[:,0],20, facecolor='b')\n",
    "# Remove the top and right spines from plot(s)\n",
    "sns.despine()\n",
    "#set labels\n",
    "plt.xlabel('RW-Nitrite '+r'(mg/L)')  \n",
    "plt.ylabel('Number of samples')  \n",
    "plt.xlim(0,300)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "#id.\n",
    "axes = plt.subplot(3,3,2)\n",
    "plt.hist(dataset_all[:,1],20, facecolor='g')\n",
    "sns.despine()\n",
    "plt.xlabel('RW-Conductivity '+r'($\\mu$s/cm)')   \n",
    "plt.xlim(200,800)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(3,3,3)\n",
    "plt.hist(dataset_all[:,2],20, facecolor='r')\n",
    "sns.despine()\n",
    "plt.xlabel('RW-pH')   \n",
    "plt.xlim(7,8.5)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(3,3,4)\n",
    "plt.hist(dataset_all[:,3],60, facecolor='c')\n",
    "sns.despine()\n",
    "plt.xlabel('RW-Turbidity '+r'(NTU)')  \n",
    "plt.ylabel('Number of samples')\n",
    "plt.xlim(0,100)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "axes = plt.subplot(3,3,5)\n",
    "plt.hist(dataset_all[:,4],20, facecolor='m')\n",
    "sns.despine()\n",
    "plt.xlabel('RW-Dissolved Oxygen '+r'(mg/L)') \n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "axes = plt.subplot(3,3,6)\n",
    "plt.hist(dataset_all[:,5],20, facecolor='y')\n",
    "sns.despine()\n",
    "plt.xlabel('SW-Turbidity '+r'(NTU)')    \n",
    "plt.xlim(0,2)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(3,3,7)\n",
    "plt.hist(dataset_all[:,6],20, facecolor='b')\n",
    "sns.despine()\n",
    "plt.xlabel('SW-Dissolved Oxygen '+'(mg/L)')  \n",
    "plt.ylabel('Number of samples')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "axes = plt.subplot(3,3,8)\n",
    "plt.hist(dataset_all[:,7],10, facecolor='purple')\n",
    "sns.despine()\n",
    "plt.xlabel('C-Turbidity '+r'(NTU)')       \n",
    "plt.xlim(0,0.5)  \n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(3,3,9)\n",
    "plt.hist(label_all,20, facecolor='k')\n",
    "sns.despine()\n",
    "plt.xlabel('Optimal coagulant dosage '+r'(mg/L)')       \n",
    "plt.xlim(0,120)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "# automatically adjusts subplot params so that the subplot(s) fits in to the figure area\n",
    "plt.tight_layout()\n",
    "\n",
    "# save .pdf\n",
    "fig.savefig('Features_histogram_pic.pdf', bbox_inches='tight', pad_inches=0.2, dpi=300)\n",
    "plt.show() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot features in a period time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random data(15.5.5-15.5.7) and non-normalized\n",
    "m.source.attr2source([('2015-05-05 00:00:00','2015-05-07 00:00:00')], 0, 0, 3, data_type='all')\n",
    "a = m.source.all_x\n",
    "b = m.source.all_y\n",
    "print ('a_shape:',a.shape)\n",
    "print ('b_shape:',b.shape)\n",
    "print (\"loading completely...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,18))\n",
    "\n",
    "axes = plt.subplot(9,1,1)\n",
    "plt.plot(a[:,0], 'r-', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.ylabel('RW-Nitrite (mg/L)')\n",
    "plt.grid(True)\n",
    "\n",
    "axes = plt.subplot(9,1,2)\n",
    "plt.plot(a[:,1], 'b-', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.ylabel('RW-Conductivity (mg/L)')\n",
    "plt.grid(True)\n",
    "\n",
    "axes = plt.subplot(9,1,3)\n",
    "plt.plot(a[:,2], 'y-', linewidth = 1.8)\n",
    "plt.ylabel('RW-pH')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(9,1,4)\n",
    "plt.plot(a[:,3], 'c-', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.ylabel('RW-Turbidity')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(9,1,5)\n",
    "plt.plot(a[:,4], 'm-', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.ylabel('RW-Dissolved Oxygen')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(9,1,6)\n",
    "plt.plot(a[:,5], 'y-', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.ylabel('SW-Turbidity')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(9,1,7)\n",
    "plt.plot(a[:,6], 'r--',linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.ylabel('SW-Dissolved Oxygen')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "axes = plt.subplot(9,1,8)\n",
    "plt.plot(a[:,7], 'y--', linewidth = 1.8)\n",
    "sns.despine()\n",
    "plt.ylabel('C-Turbidity')\n",
    "plt.grid(True)\n",
    "\n",
    "    \n",
    "plt.subplot(9,1,9)\n",
    "plt.plot(b, 'k-', linewidth = 2)\n",
    "sns.despine()\n",
    "plt.ylabel('Optimal coagulant dosage')\n",
    "plt.xlabel('Sample')\n",
    "plt.grid(True)\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "# save .pdf\n",
    "fig.savefig('Fetures_values_pic.pdf', bbox_inches='tight', pad_inches=0.2, dpi=300)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
