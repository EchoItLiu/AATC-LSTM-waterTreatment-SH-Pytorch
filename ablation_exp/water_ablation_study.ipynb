{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Study on Auto-Adjustable and Time-Consistent Long Short-Term Memory (AATC-LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "from DataSet import DataSet\n",
    "\n",
    "# Deep + ANFIS\n",
    "from models import AALSTM\n",
    "from models import LSTM\n",
    "from models import TCN\n",
    "from models import ANFIS\n",
    "import config\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import os\n",
    "import math\n",
    "import logging\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Water:\n",
    "    def __init__(self, excel_files):\n",
    "        self.source = DataSet(excel_files)\n",
    "        \n",
    "      # only init and structure model \n",
    "    \n",
    "      # Integrated: COMPLETE AATCLSTM\n",
    "      # no_AA: AATCLSTM, WHERE NO AUTO-ADJUST MECHANISM IS PERFORMED\n",
    "      # no_TC: AATCLSTM, WHERE NO TIME-CONSISTENT TERM IS PERFORMED\n",
    "      # no_AA_TC: AATCLSTM, WHERE NO AUTO-ADJUST MECHANISM AND TIME-CONSISTENT TERM ARE PERFORMED \n",
    "      # no_lambda2: AATCLSTM, WHERE NO COEFFICIENT OF REGULAR TERM LAMBDA2 IS PERFORMED\n",
    "      # no_lambda1: AATCLSTM, WHERE NO COEFFICIENT OF REGULAR TERM LAMBDA1 IS PERFORMED\n",
    "      \n",
    "    \n",
    "    def build_model(self, method, source):\n",
    "        \n",
    "        if method == 'Integrated':\n",
    "            \n",
    "            integrated_rmse = self.aalstmTraining(source, aa_flag = True, tc_flag = True, l1_flag = True, l2_flag = True)            \n",
    "            return integrated_rmse           \n",
    "                \n",
    "        if method == 'no_AA':\n",
    "            \n",
    "            no_aa_rmse = self.tclstmTraining(source, aa_flag = False, tc_flag = True, l1_flag = True, l2_flag = True)\n",
    "            return no_aa_rmse\n",
    "        \n",
    "        if method=='no_TC':\n",
    "            \n",
    "            no_tc_rmse = self.lstmTraining(source, aa_flag = True, tc_flag = False, l1_flag = True, l2_flag = True)\n",
    "            return no_tc_rmse\n",
    "                \n",
    "        if method=='no_AA_TC':\n",
    "            \n",
    "            no_aa_tc_rmse = self.lstmTraining(source, aa_flag = False, tc_flag = True, l1_flag = True, l2_flag = True)\n",
    "            return no_aa_tc_rmse\n",
    "        \n",
    "        if method=='no_lambda2':\n",
    "            \n",
    "            no_lambda2_rmse = self.tclstmTraining(source, aa_flag = True, tc_flag = True, l1_flag = True, l2_flag = False)\n",
    "            return no_lambda2_rmse\n",
    "                                           \n",
    "        if method=='no_lambda1':\n",
    "            \n",
    "            no_lambda1_rmse = self.tclstmTraining(source, aa_flag = True, tc_flag = True, l1_flag = False, l2_flag = True)\n",
    "            return no_lambda1_rmse\n",
    "\n",
    "        \n",
    "    def aalstmTraining(self, source, flag_aa, flag_tc, flag_l1, flag_l2):\n",
    "        \n",
    "        valX = source.dagger_x_test\n",
    "        valY = source.dagger_y_test           \n",
    "        val_dagger_save_metric = []\n",
    "        aatc_metric = np.zeros([4])\n",
    "        self.bestScore_dagger = 1000          \n",
    "        self.in_features = valX.size(2)\n",
    "        self.epoch = 100\n",
    "        self.batchSize_train = 128\n",
    "        self.batchSize_val = 16\n",
    "        self.trainSeq =  self.seq_abrupt = source.deep_dagger_x.size(1)\n",
    "        self.testSeq = valX.size(1)\n",
    "\n",
    "        mse_criterion = nn.MSELoss()\n",
    "                    \n",
    "        # judge L1      \n",
    "        if flag_l1==True:\n",
    "            lambda1 = [1e-3, 1e-2, 1e-1, 0, 1, 1e1]\n",
    "\n",
    "        else:\n",
    "            lambda1 = 0\n",
    "        \n",
    "        # judge L2\n",
    "        if flag_l2==True:\n",
    "            lambda2 = [1e-3, 1e-2, 1e-1, 0, 1, 1e1]\n",
    "            \n",
    "        else:\n",
    "            lambda2 = 0\n",
    "        \n",
    "        # judge AA\n",
    "        if flag_aa==True:\n",
    "            aalstm = AALSTM(self.in_features, self.trainSeq, self.testSeq).cuda().double()\n",
    "       \n",
    "        else:\n",
    "            aalstm = LSTM(self.in_features, self.trainSeq, self.testSeq).cuda().double()\n",
    "        \n",
    "        \n",
    "        optimizer_dagger = torch.optim.Adam(aalstm.parameters(), lr = 1e-2)\n",
    "\n",
    "\n",
    "        loss_aatc_save = []\n",
    "        loss_dag_sum = 0\n",
    "        count_dag = 0\n",
    "\n",
    "        for i in range(self.epoch):\n",
    "\n",
    "            be_idx = 0\n",
    "\n",
    "            if i==0:\n",
    "                trainX_dag = source.deep_dagger_x\n",
    "                trainY_dag = source.deep_dagger_y\n",
    "            else:\n",
    "                trainX_dag = source.dagger_shuffle[:,:,:-1]\n",
    "                trainY_dag = source.dagger_shuffle[:,:,-1]\n",
    "\n",
    "            while(be_idx + self.batchSize_train) <= (trainX_dag.size(0) - 1):\n",
    "                optimizer_dagger.zero_grad()\n",
    "                \n",
    "                ed_idx = be_idx + self.batchSize_trainã€                \n",
    "                out = aalstm(trainX_dag[be_idx:ed_idx,:,:], trainY_dag[be_idx:ed_idx,:], True)\n",
    "                \n",
    "                # judge TC \n",
    "                if flag_tc == True:           \n",
    "                    AD_rate = cal_AC(trainX_dag[be_idx:(ed_idx + 1),:,:], self.batch_size_train, self.seq_train, 'batch')         \n",
    "\n",
    "                else:\n",
    "                    AD_rate = 1                \n",
    "\n",
    "                dag_params1 = aalstm.parameters()\n",
    "                L1_dag_sum = self.sum_params4L(dag_params1, 'L1')\n",
    "                dag_params2 = aalstm.parameters()\n",
    "                L2_dag_sum = self.sum_params4L(dag_params2, 'L2')\n",
    "\n",
    "\n",
    "                # Total Loss (TC Term)\n",
    "                loss_dag = AD_rate * mse_criterion(out, trainY_dag[be_idx:ed_idx,:]) + lambda1[1] * L1_dag_sum \\\n",
    "                + lambda2[2] * L2_dag_sum\n",
    "\n",
    "                loss_dag.backward()\n",
    "                optimizer_dagger.step()\n",
    "                loss_dag_sum = loss_dag + loss_dag_sum                    \n",
    "                be_idx = ed_idx\n",
    "                count_dag = count_dag + 1\n",
    "\n",
    "            average_dag_loss = loss_dag_sum / count_dag\n",
    "            epoch_num = 'epoch' + str(i)\n",
    "            loss_aatc_save.append(average_dag_loss)\n",
    "\n",
    "            loss_dag_sum = 0\n",
    "            count_dag = 0\n",
    "\n",
    "\n",
    "            ## validation\n",
    "            if i >= 5 and i%5==0:\n",
    "\n",
    "                batch_dag_val_b = 0\n",
    "                rmse_dag_score_total = 0\n",
    "                mape_dag_score_total = 0\n",
    "                corr_dag_score_total = 0\n",
    "                wi_dag_score_total = 0\n",
    "                count_dag_val = 0\n",
    "\n",
    "                val_oneBatch_dagger_metric = np.zeros([4])\n",
    "\n",
    "                while (batch_dag_val_b + self.batchSize_val) <= valX.size(0):\n",
    "                    with torch.no_grad():\n",
    "                        batch_dag_val_e = batch_dag_val_b + self.batchSize_val\n",
    "                        valXSlice = valX[batch_dag_val_b:batch_dag_val_e,:,:]\n",
    "                        valYSlice = valY[batch_dag_val_b:batch_dag_val_e]\n",
    "\n",
    "                        val_dag_out = daggertenlar(valXSlice, valYSlice, False)\n",
    "\n",
    "                        # calculate metrics for deep\n",
    "                        rmse_dag_score = self.cal_rmse4deep(val_dag_out, valYSlice, 'rmse')\n",
    "                        mape_dag_score = self.cal_rmse4deep(val_dag_out, valYSlice, 'mape')\n",
    "                        corr_dag_score = self.cal_rmse4deep(val_dag_out, valYSlice, 'correlation')\n",
    "                        wi_dag_score = self.cal_rmse4deep(val_dag_out, valYSlice, 'wi')\n",
    "\n",
    "                        rmse_dag_score_total = rmse_dag_score_total + rmse_dag_score\n",
    "                        mape_dag_score_total = mape_dag_score_total + mape_dag_score\n",
    "                        corr_dag_score_total = corr_dag_score_total + corr_dag_score\n",
    "                        wi_dag_score_total = wi_dag_score_total + wi_dag_score\n",
    "\n",
    "                        batch_dag_val_b = batch_dag_val_e\n",
    "                        count_dag_val = count_dag_val + 1\n",
    "\n",
    "                #     \n",
    "                val_oneBatch_dagger_metric[0] = rmse_dag_av_score = rmse_dag_score_total / count_dag_val\n",
    "                val_oneBatch_dagger_metric[1] = mape_dag_av_score = mape_dag_score_total / count_dag_val\n",
    "                val_oneBatch_dagger_metric[2] = corr_dag_av_score = corr_dag_score_total / count_dag_val\n",
    "                val_oneBatch_dagger_metric[3] = wi_dag_av_score = wi_dag_score_total / count_dag_val                       \n",
    "\n",
    "    #     \n",
    "\n",
    "                if rmse_dag_av_score < self.bestScore_dagger:\n",
    "                    print ('validation_dagger_best_score:', rmse_dag_av_score)\n",
    "                    print ('current_best_epoch:', i)\n",
    "\n",
    "                    val_dagger_save_metric.append(val_oneBatch_dagger_metric)\n",
    "                    self.bestScore_dagger = rmse_dag_av_score\n",
    "        # \n",
    "        val_save_metric_dagger = np.concatenate(val_dagger_save_metric)\n",
    "        val_save_metric_dagger = val_save_metric_dagger.reshape(-1, 4)\n",
    "\n",
    "        for i in range(val_save_metric_dagger.shape[1]):\n",
    "            val_save_metric_dagger_slice = val_save_metric_dagger[:, i]\n",
    "            val_save_metric_dagger_slice.sort(0)\n",
    "\n",
    "            if i==0 or i==1:\n",
    "                aatc_metric[i] = val_save_metric_dagger_slice[0][i]\n",
    "            else:\n",
    "                aatc_metric[i] = val_save_metric_dagger_slice[-1][i]\n",
    "                \n",
    "         # selecting RMSE\n",
    "         aatc_rmse = aatc_metric[0]\n",
    "                       \n",
    "        return aatc_rmse   \n",
    "\n",
    "    \n",
    "    \n",
    "    def evaluate(self, pred_y, true_y, metrics):\n",
    "        pred_y = pred_y.reshape([-1])\n",
    "        true_y = true_y.reshape([-1])\n",
    "        metrics_num = len(metrics)\n",
    "        results = np.zeros([metrics_num])\n",
    "        for i,metric in enumerate(metrics):\n",
    "            if metric == 'rmse':\n",
    "                results[i] = np.sqrt(np.mean(np.power(pred_y - true_y,2)))\n",
    "            elif metric == 'mape':\n",
    "                results[i] = np.mean(np.abs(true_y - pred_y) / true_y)*100\n",
    "            elif metric == 'correlation':\n",
    "                results[i] = np.corrcoef(pred_y, true_y)[0,1]\n",
    "            elif metric == 'wi':\n",
    "                results[i] = np.sum(np.power(true_y - pred_y, 2)) / np.sum(np.power(np.abs(pred_y - np.mean(true_y)) + np.abs(true_y-np.mean(true_y)), 2))\n",
    "        return results      \n",
    "          \n",
    "        \n",
    "    def run_experiments(self, methods, experiments, repeat_num, metrics):\n",
    "        # dic type\n",
    "        results = {}\n",
    "        for exp_name in experiments.keys():\n",
    "            # exp_name is dict_keys type\n",
    "            exp = experiments[exp_name]\n",
    "            train_time, test_time = exp['times']\n",
    "            evaluation = np.zeros([repeat_num, len(exp['lag_time']), len(exp['clustering']), len(exp['normalize']), len(methods), (len(metrics)-3)])\n",
    "            print ('repeat_num:',repeat_num)\n",
    "                        \n",
    "            for r in range(repeat_num):\n",
    "                for i,lag_time in enumerate(exp['lag_time']):\n",
    "                    for j,clustering in enumerate(exp['clustering']):\n",
    "                        for k,normalize in enumerate(exp['normalize']):\n",
    "                            \n",
    "                                    # time-series data\n",
    "                            self.source.attr2source(train_time, \n",
    "                                                    normalize,\n",
    "                                                    0, \n",
    "                                                    lag_time,\n",
    "                                                    data_type = 'time-series')                            \n",
    "                            \n",
    "                            # general training data\n",
    "                            self.source.attr2source(train_time, \n",
    "                                                    normalize,\n",
    "                                                    clustering, \n",
    "                                                    lag_time,\n",
    "                                                    data_type = 'ts-train')\n",
    "                            # general testing data\n",
    "                            self.source.attr2source(test_time,\n",
    "                                                     normalize, \n",
    "                                                     clustering, \n",
    "                                                     lag_time,\n",
    "                                                     data_type = 'ts-test')\n",
    "                                                    \n",
    "                   \n",
    "                            # print and saving all ablative models\n",
    "                            for t, method in enumerate(methods):\n",
    "                                                \n",
    "                                evaluation[r, i, j, k, t, :] = self.build_model(method, self.source) \n",
    "               \n",
    "                                print('exp_name={}, lag_time={}, normalize={}, clustering={}, method={} :{}'.format(\n",
    "                                    exp_name, lag_time, normalize, clustering, method, evaluation[r, i, j, k, t, :]))\n",
    "                                \n",
    "            # save results as a dictionary \n",
    "            np.save('result/{}.npy'.format(exp_name), evaluation)            \n",
    "\n",
    "\n",
    "    def decimal2round2(self, results):\n",
    "        sh = results.shape\n",
    "        fraction = results.reshape(-1)\n",
    "        for m in range(len(fraction)):\n",
    "            fraction[m] = round(fraction[m],8)\n",
    "        fractions = fraction.reshape(sh)\n",
    "#         print ('fractions_shape',fractions.shape)\n",
    "        return fractions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(config_ablation.path)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "m = Water(config_ablation.excel_files)\n",
    "m.run_experiments(config_ablation.methods, \n",
    "                  config_ablation.experiments,\n",
    "                  config_ablation.repeat_num,\n",
    "                  config_ablation.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating dRMSE\n",
    "## $dRMSE = {\\vert RMSE - RMSE_{w/o} \\vert}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/o TC: 0.29\n",
      "w/o lambda_2: 0.1\n",
      "w/o lambda_1: 0.05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loading Spring as ablative dataset\n",
    "results_spring = np.load(osp.join('result', 'spring.npy'))\n",
    "result_spring  = results_spring.mean(0).squeeze()\n",
    "\n",
    "# RMSE\n",
    "RMSE = result_spring[0]\n",
    "\n",
    "# calculating dRMSE \n",
    "dRMSE_no_aa = np.abs(RMSE - result_spring[1]) \n",
    "dRMSE_no_tc = np.abs(RMSE - result_spring[2]) \n",
    "dRMSE_no_aa = np.abs(RMSE - result_spring[3]) \n",
    "dRMSE_no_aa_tc = np.abs(RMSE - result_spring[4]) \n",
    "dRMSE_no_lambda2 = np.abs(RMSE - result_spring[5])\n",
    "dRMSE_no_lambda1 = np.abs(RMSE - result_spring[6]) \n",
    "\n",
    "print ('w/o TC:', dRMSE_no_tc)\n",
    "print ('w/o lambda_2:', dRMSE_no_lambda2)\n",
    "print ('w/o lambda_1:', dRMSE_no_lambda1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
